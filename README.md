# AnÃ¡lisis de MorfologÃ­a Mitocondrial - CT vs ELA# AnÃ¡lisis de MorfologÃ­a Mitocondrial



## ğŸ“Š DescripciÃ³n del Proyecto## ğŸ“Š DescripciÃ³n del Proyecto



Proyecto de clasificaciÃ³n supervisada que utiliza **deep learning con LSTM** para distinguir participantes Control (CT) vs Esclerosis Lateral AmiotrÃ³fica (ELA) basÃ¡ndose en mÃ©tricas morfolÃ³gicas mitocondriales.Este proyecto analiza mÃ©tricas morfolÃ³gicas de mitocondrias para identificar patrones y diferencias entre grupos de estudio (Control vs ELA). Utilizamos tÃ©cnicas de anÃ¡lisis exploratorio, reducciÃ³n dimensional (PCA) y deep learning (Autoencoder) para visualizar el espacio latente y detectar posibles clusterizaciones.



**CaracterÃ­sticas principales:**### MÃ©tricas Analizadas

- **Dataset pequeÃ±o**: 20 participantes (10 CT, 10 ELA) con secuencias de longitud variable (4-36 mediciones)

- **K-Fold Cross-Validation**: Entrenamiento robusto con validaciÃ³n cruzada estratificadaLos datos contienen las siguientes mÃ©tricas por mitocondria:

- **LSTM Bidireccional**: Captura patrones en secuencias de mediciones

- **ClasificaciÃ³n binaria**: CT (clase 0) vs ELA (clase 1)- **N mitocondrias**: NÃºmero de mitocondrias analizadas

- **IsoVol (SUMA/PROM)**: Volumen isomÃ©trico total y promedio

### ğŸ“ MÃ©tricas MorfolÃ³gicas Analizadas- **Surface (SUMA/PROM)**: Superficie total y promedio

- **Length (SUMA/PROM)**: Longitud total y promedio

**8 features de entrada** (todas agregadas SUMA/PROM por mitocondria):- **RoughSph (SUMA/PROM)**: Ãndice de rugosidad/esfericidad total y promedio

- **IsoVol**: Volumen isomÃ©trico- **Variables demogrÃ¡ficas**: Age, Sex, Group (CT/ELA), Participant

- **Surface**: Ãrea de superficie

- **Length**: Longitud## ğŸ¯ Objetivos

- **RoughSph**: Ãndice de rugosidad/esfericidad

1. **AnÃ¡lisis Exploratorio**: Examinar distribuciones y diferencias entre grupos (CT vs ELA), sexos y participantes

**Variables demogrÃ¡ficas** (NO usadas como input del modelo):2. **PCA (AnÃ¡lisis de Componentes Principales)**: Reducir dimensionalidad y visualizar la varianza explicada

- Age, Sex, Group (CT/ELA), Participant, n_mitochondrias3. **Autoencoder**: Entrenar una red neuronal para comprimir la informaciÃ³n y explorar el espacio latente

4. **VisualizaciÃ³n**: Identificar si existe clusterizaciÃ³n natural de los datos segÃºn caracterÃ­sticas morfolÃ³gicas

## ğŸ¯ Objetivos

## ğŸ—ï¸ Estructura del Proyecto

1. **ClasificaciÃ³n Supervisada**: Predecir correctamente participantes CT vs ELA usando solo morfologÃ­a mitocondrial

2. **AnÃ¡lisis Exploratorio**: Examinar distribuciones y diferencias entre grupos```

3. **ReducciÃ³n Dimensional**: Visualizar patrones con PCA (lineal) y explorar separabilidadmitochondrial-morphology/

4. **K-Fold Cross-Validation**: Obtener mÃ©tricas robustas (mean Â± std) para datasets pequeÃ±osâ”‚

â”œâ”€â”€ data/

## ğŸ—ï¸ Estructura del Proyectoâ”‚   â””â”€â”€ data.csv                    # Dataset original

â”‚

```â”œâ”€â”€ src/

mitochondrial-morphology/â”‚   â”œâ”€â”€ __init__.py

â”‚â”‚   â”œâ”€â”€ data_loader.py              # Carga y preprocesamiento de datos

â”œâ”€â”€ data/â”‚   â”œâ”€â”€ pca_analysis.py             # ImplementaciÃ³n del PCA

â”‚   â””â”€â”€ data.csv                    # Dataset (306 muestras, 20 participantes)â”‚   â”œâ”€â”€ autoencoder.py              # Arquitectura del Autoencoder (PyTorch Lightning)

â”‚â”‚   â””â”€â”€ utils.py                    # Funciones auxiliares y visualizaciÃ³n

â”œâ”€â”€ src/â”‚

â”‚   â”œâ”€â”€ __init__.pyâ”œâ”€â”€ pages/

â”‚   â”œâ”€â”€ data_loader.py              # Carga y preprocesamientoâ”‚   â”œâ”€â”€ 1_ğŸ“Š_EDA.py                 # PÃ¡gina de AnÃ¡lisis Exploratorio

â”‚   â”œâ”€â”€ pca_analysis.py             # AnÃ¡lisis PCAâ”‚   â”œâ”€â”€ 2_ï¿½_Entrenar_Modelo.py     # PÃ¡gina de Entrenamiento con TensorBoard

â”‚   â”œâ”€â”€ classifier.py               # LSTM Classifier (PyTorch Lightning)â”‚   â””â”€â”€ 3_ğŸ¤–_Autoencoder.py         # PÃ¡gina de VisualizaciÃ³n de Modelos

â”‚   â””â”€â”€ utils.py                    # Funciones auxiliaresâ”‚

â”‚â”œâ”€â”€ scripts/

â”œâ”€â”€ pages/â”‚   â””â”€â”€ train_autoencoder.py        # Script para entrenar el autoencoder

â”‚   â”œâ”€â”€ 1_ğŸ“Š_EDA.py                 # AnÃ¡lisis Exploratorioâ”‚

â”‚   â”œâ”€â”€ 2_ğŸ¯_PCA.py                 # PCA (participante + individual)â”œâ”€â”€ models/

â”‚   â”œâ”€â”€ 3_ğŸ“_Entrenar_Modelo.py     # Entrenamiento (simple split o K-Fold)â”‚   â””â”€â”€ .gitkeep                    # Modelos entrenados guardados aquÃ­

â”‚   â””â”€â”€ 4_ğŸ¤–_Clasificador.py        # VisualizaciÃ³n de resultadosâ”‚

â”‚â”œâ”€â”€ logs/

â”œâ”€â”€ scripts/â”‚   â””â”€â”€ .gitkeep                    # Logs de TensorBoard (Lightning)

â”‚   â””â”€â”€ train_classifier.py         # Script de entrenamiento (CLI)â”‚

â”‚â”œâ”€â”€ config/

â”œâ”€â”€ models/â”‚   â””â”€â”€ config.yaml                 # ConfiguraciÃ³n del proyecto

â”‚   â”œâ”€â”€ *.ckpt                      # Modelos entrenados (simple split)â”‚

â”‚   â””â”€â”€ kfold_K/                    # Modelos K-Fold + summary.jsonâ”œâ”€â”€ app.py                          # AplicaciÃ³n Streamlit principal (home)

â”‚â”œâ”€â”€ requirements.txt                # Dependencias del proyecto

â”œâ”€â”€ logs/â”œâ”€â”€ .gitignore                      # Archivos a ignorar en Git

â”‚   â””â”€â”€ lstm_classifier/            # TensorBoard logsâ””â”€â”€ README.md                       # Este archivo

â”‚```

â”œâ”€â”€ config/

â”‚   â””â”€â”€ config.yaml                 # ConfiguraciÃ³n del proyecto### JustificaciÃ³n de la Estructura

â”‚

â”œâ”€â”€ app.py                          # Punto de entrada Streamlit- **`src/`**: MÃ³dulos reutilizables para anÃ¡lisis y modelado (backend lÃ³gico)

â”œâ”€â”€ README.md                       # Este archivo- **`pages/`**: PÃ¡ginas de Streamlit - arquitectura multi-page nativa de Streamlit

â””â”€â”€ requirements.txt                # Dependencias Python- **`scripts/`**: Scripts Python ejecutables (ej: entrenamiento del autoencoder)

```- **`models/`**: Checkpoints del autoencoder entrenado (generados por PyTorch Lightning)

- **`logs/`**: Logs de TensorBoard generados automÃ¡ticamente por PyTorch Lightning

## ğŸš€ Quick Start- **`config/`**: Archivo YAML centralizado con todos los parÃ¡metros del proyecto

- **`app.py`**: PÃ¡gina principal de Streamlit (home), punto de entrada de la aplicaciÃ³n

### 1. Instalar dependencias

```bash## ğŸš€ InstalaciÃ³n y Uso

# Crear entorno virtual (recomendado)

python -m venv venv### Prerrequisitos

source venv/bin/activate  # Linux/Mac

# venv\Scripts\activate  # Windows- Python 3.8+

- pip o conda

# Instalar dependencias

pip install -r requirements.txt### 1. Clonar el Repositorio

```

```bash

### 2. Ejecutar la aplicaciÃ³ngit clone <URL_DEL_REPOSITORIO>

```bashcd mitochondrial-morphology

streamlit run app.py```

```

### 2. Crear Entorno Virtual (Recomendado)

La aplicaciÃ³n se abrirÃ¡ en `http://localhost:8501`

```bash

### 3. NavegaciÃ³npython -m venv venv

source venv/bin/activate  # En Windows: venv\Scripts\activate

**PÃ¡ginas disponibles:**```



1. **ğŸ“Š EDA (AnÃ¡lisis Exploratorio)**### 3. Instalar Dependencias

   - EstadÃ­sticas descriptivas

   - Distribuciones por grupo (CT vs ELA)```bash

   - Correlaciones entre variablespip install -r requirements.txt

   - AnÃ¡lisis por participante```



2. **ğŸ¯ PCA (AnÃ¡lisis de Componentes Principales)**### 4. Ejecutar la AplicaciÃ³n Streamlit

   - PCA a nivel participante (agregado por participant)

   - PCA a nivel individual (todas las mediciones)```bash

   - VisualizaciÃ³n 2D/3D interactivastreamlit run app.py

   - Varianza explicada```



3. **ğŸ“ Entrenar Modelo**La aplicaciÃ³n se abrirÃ¡ en tu navegador (por defecto: `http://localhost:8501`)

   - **Train/Val Split Simple** (80/20)

   - **K-Fold Cross-Validation** (K=3-10, recomendado K=5)**NavegaciÃ³n**: La aplicaciÃ³n usa la arquitectura multi-page de Streamlit:

   - ConfiguraciÃ³n de hiperparÃ¡metros:- **Home (app.py)**: PÃ¡gina principal con descripciÃ³n del proyecto

     - Max epochs, batch size, learning rate- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo

     - Hidden dim, num layers, dropout- **ï¿½ Entrenar Modelo**: Entrenar VAE/LSTM-VAE con TensorBoard en tiempo real

     - Early stopping, checkpointing- **ğŸ¤– Autoencoder**: VisualizaciÃ³n del espacio latente y mÃ©tricas

   - Resultados en tiempo real

### 5. Entrenar el Autoencoder

4. **ğŸ¤– Clasificador (Resultados)**

   - Accuracy, confusion matrixPuedes entrenar el autoencoder de dos formas:

   - Classification report (precision, recall, F1)

   - DistribuciÃ³n de probabilidades**OpciÃ³n A - Desde la interfaz web (Recomendado)**:

   - AnÃ¡lisis por participante1. Ejecuta la app: `streamlit run app.py`

   - MÃ©tricas de entrenamiento (loss, accuracy)2. Ve a la pÃ¡gina "ğŸ“ Entrenar Modelo"

3. Selecciona el tipo de modelo:

## ğŸ§  Arquitectura del Modelo   - **VAE EstÃ¡ndar**: Agrega mediciones por participante (mean pooling)

   - **LSTM-VAE**: Preserva variabilidad intra-participante (secuencias completas)

### LSTM Classifier4. Configura hiperparÃ¡metros (epochs, learning rate, batch size, patience)

5. Haz clic en "ğŸš€ Iniciar Entrenamiento"

```6. **TensorBoard se abre automÃ¡ticamente en la misma pÃ¡gina** mostrando mÃ©tricas en tiempo real

Input: (batch, seq_len, 8)  [8 features morfomÃ©tricas]

           â†“**OpciÃ³n B - Desde la terminal**:

Bidirectional LSTM (2 layers, hidden_dim=64)```bash

           â†“# VAE estÃ¡ndar

Concatenate [forward_hidden, backward_hidden]python scripts/train_autoencoder.py

           â†“

Fully Connected: 128 â†’ ReLU â†’ Dropout(0.3)# LSTM-VAE (preserva variabilidad intra-participante)

           â†“python scripts/train_autoencoder.py --lstm

Fully Connected: 64 â†’ ReLU â†’ Dropout(0.3)```

           â†“

Fully Connected: 32 â†’ ReLU â†’ Dropout(0.3)### 6. Ver Logs de TensorBoard

           â†“

Output: (batch, 2)  [logits para CT/ELA]**Durante el entrenamiento desde Streamlit**: TensorBoard se muestra automÃ¡ticamente en un iframe embebido.

```

**Manualmente** (opcional):

**CaracterÃ­sticas:**```bash

- **Input variable**: Acepta secuencias de longitud variable (4-36 mediciones/participante)tensorboard --logdir=logs/

- **Bidireccional**: Captura patrones en ambas direcciones```

- **RegularizaciÃ³n**: Dropout para prevenir overfitting

- **Loss**: Cross EntropyAbre tu navegador en `http://localhost:6006` para ver mÃ©tricas de entrenamiento, grÃ¡ficos de pÃ©rdida, y mÃ¡s.

- **Optimizer**: Adam con learning rate scheduler (ReduceLROnPlateau)

- **ParÃ¡metros**: ~147K trainable params## ğŸ“ˆ Estrategia de AnÃ¡lisis



## ğŸ“Š Dataset### Fase 1: AnÃ¡lisis Exploratorio de Datos (EDA)



- **Total muestras**: 306 mediciones**Objetivo**: Comprender la distribuciÃ³n y relaciones de las mÃ©tricas

- **Participantes**: 20 (10 CT, 10 ELA)

- **DistribuciÃ³n por grupo**:**TÃ©cnicas**:

  - CT: 167 samples, 10 participants- EstadÃ­sticas descriptivas por grupo (CT vs ELA)

  - ELA: 139 samples, 10 participants- Visualizaciones:

- **Secuencias**: Longitud variable por participante (min: 4, max: 36)  - Distribuciones (histogramas, boxplots) por grupo y sexo

- **Features**: 8 mÃ©tricas morfolÃ³gicas (IsoVol, Surface, Length, RoughSph - SUMA/PROM)  - Matrices de correlaciÃ³n

  - Pairplots para variables clave

## ğŸ”¬ K-Fold Cross-Validation- Pruebas estadÃ­sticas (t-test, ANOVA) para diferencias entre grupos



### Â¿Por quÃ© K-Fold para 20 participantes?**Herramientas**: Pandas, Seaborn, Plotly (para interactividad en Streamlit)



**Problema con train/val split simple:**### Fase 2: PCA (ReducciÃ³n Dimensional)

- Solo 16 participantes para entrenar (1 modelo)

- Sensible al split aleatorio (puede ser "fÃ¡cil" o "difÃ­cil" por suerte)**Objetivo**: Identificar las componentes principales que explican la mayor varianza

- 1 mÃ©trica (ej: 75% accuracy) â†’ Â¿es representativa?

**Proceso**:

**SoluciÃ³n con K-Fold (K=5):**1. NormalizaciÃ³n de features (StandardScaler)

- Entrena 5 modelos independientes2. Aplicar PCA y visualizar varianza explicada (scree plot)

- Cada participante se valida exactamente 1 vez3. Proyectar datos en 2D/3D (PC1 vs PC2 vs PC3)

- MÃ©tricas robustas: **Mean Â± Std** (ej: 60% Â± 12%)4. Colorear por grupo, sexo y participante para identificar patrones

- Refleja mejor la generalizaciÃ³n real

**InterpretaciÃ³n**: 

**Ejemplo con K=5:**- Â¿Se separan los grupos CT y ELA en el espacio PCA?

```- Â¿QuÃ© mÃ©tricas contribuyen mÃ¡s a cada componente?

Fold 1: Train [16 participants] â†’ Val [4 participants]

Fold 2: Train [16 participants] â†’ Val [4 participants] (diferentes)### Fase 3: Variational Autoencoder (VAE) con PyTorch Lightning

Fold 3: Train [16 participants] â†’ Val [4 participants] (diferentes)

Fold 4: Train [16 participants] â†’ Val [4 participants] (diferentes)**Objetivo**: Aprender una representaciÃ³n probabilÃ­stica comprimida del espacio latente

Fold 5: Train [16 participants] â†’ Val [4 participants] (diferentes)

**Dos Arquitecturas Disponibles**:

Resultado final: Val Accuracy = Mean(Fold1, ..., Fold5) Â± Std

```#### 1. VAE EstÃ¡ndar (Mean Pooling)

```

### CuÃ¡ndo usar cada modoInput (8 features agregadas) â†’ Encoder [64, 32] â†’ Latent 8D (Î¼, Ïƒ) â†’ Decoder [32, 64] â†’ Output (8 features)

                                                        â†“

| Modo | CuÃ¡ndo usar | Ventajas | Desventajas |                                                 Classifier [16] â†’ CT/ELA

|------|-------------|----------|-------------|```

| **Simple Split** | Testing rÃ¡pido, datasets grandes (N>100) | RÃ¡pido (1 modelo) | Menos robusto para N pequeÃ±o |- **Ventaja**: RÃ¡pido, simple, interpretable

| **K-Fold** | Datasets pequeÃ±os (N<100), reportes cientÃ­ficos | MÃ©tricas robustas, menos sesgo | MÃ¡s lento (K modelos) |- **Desventaja**: Pierde variabilidad intra-participante



## ğŸ“ Entrenamiento#### 2. LSTM-VAE (Sequences)

```

### OpciÃ³n 1: Desde Streamlit (Recomendado)Input (secuencias 4-36 mediciones Ã— 8 features) â†’ Bidirectional LSTM Encoder (2 capas, hidden=64)

                                                        â†“

1. Ejecutar `streamlit run app.py`                                                 Latent 16D (Î¼, Ïƒ)

2. Ir a pÃ¡gina **ğŸ“ Entrenar Modelo**                                                        â†“

3. Seleccionar modo:                                          Decoder LSTM (2 capas, hidden=64)

   - **Train/Val Split Simple** (rÃ¡pido)                                                        â†“

   - **K-Fold Cross-Validation** (robusto)                                          Output (secuencias reconstruidas)

4. Configurar hiperparÃ¡metros                                                        â†“

5. Click en **ğŸš€ Iniciar Entrenamiento**                                          Classifier [32, 16] â†’ CT/ELA

6. Ver resultados en pÃ¡gina **ğŸ¤– Clasificador**```

- **Ventaja**: Preserva variabilidad intra-participante, mayor capacidad

### OpciÃ³n 2: Desde terminal- **Desventaja**: MÃ¡s lento, mÃ¡s parÃ¡metros (~205k vs ~6k)



```bash**ConfiguraciÃ³n**:

# Entrenamiento con K-Fold (K=5)- **Framework**: PyTorch Lightning (simplifica entrenamiento, logging automÃ¡tico)

python scripts/train_classifier.py- **Loss**: ReconstrucciÃ³n + KL Divergence + ClasificaciÃ³n

- **Optimizer**: Adam con learning rate configurable

# Ver mÃ©tricas con TensorBoard- **Logging**: TensorBoard embebido en Streamlit (tiempo real)

tensorboard --logdir logs/lstm_classifier- **Callbacks**: Early Stopping, ModelCheckpoint, LearningRateMonitor

```

**Monitoreo en Tiempo Real**:

## ğŸ“ˆ InterpretaciÃ³n de Resultados- TensorBoard se muestra **dentro de Streamlit** durante el entrenamiento

- MÃ©tricas: loss, accuracy, KL divergence, reconstruction error

### MÃ©tricas K-Fold- Visualizaciones: curvas de aprendizaje, histogramas de pesos



**Ejemplo:** Val Accuracy: 60% Â± 12%**VisualizaciÃ³n**:

- ProyecciÃ³n del espacio latente en 2D/3D por grupo (CT/ELA)

- **Mean (60%)**: Accuracy promedio esperada en nuevos participantes- MÃ©tricas de clasificaciÃ³n (accuracy, confusion matrix)

- **Std (12%)**: Variabilidad entre folds- Comparar reconstrucciones vs datos originales

  - **Std < 10%**: Modelo estable âœ…- Identificar si la variabilidad intra-participante mejora la clasificaciÃ³n

  - **Std > 15%**: Alta variabilidad (normal con N=20) âš ï¸

### Fase 4: IntegraciÃ³n en Streamlit

### Accuracy Guidelines

**Arquitectura Multi-Page de Streamlit**:

| Accuracy | InterpretaciÃ³n |

|----------|----------------|La aplicaciÃ³n utiliza la estructura nativa de mÃºltiples pÃ¡ginas de Streamlit:

| **>70%** | âœ… Excelente - Hay seÃ±al morfomÃ©trica clara entre CT/ELA |

| **60-70%** | âš¡ Bueno - Hay separabilidad, puede mejorar con tuning |1. **Home (app.py)**: 

| **50-60%** | âš ï¸ Regular - Poco mejor que azar, revisar features |   - DescripciÃ³n del proyecto y dataset

| **<50%** | âŒ Malo - Modelo no estÃ¡ aprendiendo |   - MÃ©tricas generales

   - Vista previa de los datos

### Outputs guardados

2. **ğŸ“Š EDA (pages/1_ğŸ“Š_EDA.py)**:

**Simple Split:**   - SelecciÃ³n interactiva de mÃ©tricas y grupos

```   - GrÃ¡ficos de distribuciÃ³n (box, violin, histogram)

models/   - Matriz de correlaciÃ³n interactiva

â”œâ”€â”€ lstm_classifier-epoch=XX-val_acc=X.XXXX.ckpt   - Pruebas estadÃ­sticas automÃ¡ticas (t-test/ANOVA)

â””â”€â”€ ...   - Scatter plot matrix

   - AnÃ¡lisis por edad y participante

logs/lstm_classifier/

â””â”€â”€ version_0/3. **ï¿½ Entrenar Modelo (pages/2_ï¿½_Entrenar_Modelo.py)** â­ **NUEVO**:

    â””â”€â”€ events.out.tfevents...   - SelecciÃ³n de tipo de modelo (VAE estÃ¡ndar vs LSTM-VAE)

```   - ConfiguraciÃ³n interactiva de hiperparÃ¡metros:

     - Max epochs, learning rate, batch size, early stopping patience

**K-Fold:**   - **TensorBoard embebido en tiempo real** durante el entrenamiento

```   - VisualizaciÃ³n de mÃ©tricas: loss, accuracy, KL divergence

models/kfold_5/   - Ver entrenamientos anteriores y comparar runs

â”œâ”€â”€ fold1-epoch=XX-val_acc=X.XXXX.ckpt   - GuÃ­as contextuales sobre arquitecturas y hiperparÃ¡metros

â”œâ”€â”€ fold2-epoch=XX-val_acc=X.XXXX.ckpt   - Todo integrado - no necesitas abrir terminales adicionales

â”œâ”€â”€ ...

â””â”€â”€ summary.json  â† MÃ©tricas agregadas + hiperparÃ¡metros4. **ğŸ¤– Autoencoder (pages/3_ğŸ¤–_Autoencoder.py)**:

   - Carga de modelos entrenados (VAE o LSTM-VAE)

logs/lstm_classifier_kfold_5/   - DetecciÃ³n automÃ¡tica del tipo de modelo

â”œâ”€â”€ fold_1/   - VisualizaciÃ³n del espacio latente 2D/3D (Plotly interactivo)

â”œâ”€â”€ fold_2/   - MÃ©tricas de clasificaciÃ³n (accuracy, confusion matrix)

â””â”€â”€ ...   - AnÃ¡lisis de reconstrucciones

```   - ComparaciÃ³n conceptual con PCA

   - ExportaciÃ³n del espacio latente

## ğŸ› ï¸ Stack TecnolÃ³gico   - Ver logs histÃ³ricos de TensorBoard



| TecnologÃ­a | PropÃ³sito |**Ventajas de esta arquitectura**:

|-----------|-----------|- âœ… Todo nativo en Streamlit (sin necesidad de frameworks adicionales)

| **PyTorch** | Deep learning framework |- âœ… NavegaciÃ³n automÃ¡tica mediante sidebar

| **PyTorch Lightning** | Training loop, callbacks, logging |- âœ… Cache de datos para mejor rendimiento

| **Streamlit** | Web app interactiva |- âœ… Visualizaciones interactivas con Plotly

| **TensorBoard** | VisualizaciÃ³n de mÃ©tricas |- âœ… **TensorBoard embebido en tiempo real** - sin abrir ventanas adicionales

| **scikit-learn** | PCA, cross-validation, metrics |- âœ… Entrenamiento del modelo integrado en la UI

| **Plotly** | GrÃ¡ficos interactivos 3D |- âœ… ComparaciÃ³n fÃ¡cil entre VAE estÃ¡ndar y LSTM-VAE

| **Pandas/NumPy** | ManipulaciÃ³n de datos |- âœ… Logs nativos de PyTorch Lightning visibles en TensorBoard

- âœ… Workflow completo: configurar â†’ entrenar â†’ monitorear â†’ visualizar

## âš™ï¸ HiperparÃ¡metros Recomendados

## ğŸ†• CaracterÃ­sticas Destacadas

### Para empezar (baseline)

### TensorBoard en Tiempo Real

```yaml

hidden_dim: 64La nueva pÃ¡gina de entrenamiento incluye **TensorBoard embebido** que muestra mÃ©tricas en tiempo real:

num_layers: 2

dropout: 0.3- ğŸ“Š **Curvas de aprendizaje**: Loss y accuracy (train/validation)

learning_rate: 1e-3- ğŸ“ˆ **KL Divergence**: RegularizaciÃ³n del espacio latente

batch_size: 16- ğŸ” **Reconstruction Loss**: Calidad de reconstrucciÃ³n

max_epochs: 50-100- ğŸ¯ **Classification Metrics**: Accuracy de CT vs ELA

```- ğŸ“‰ **Learning Rate**: EvoluciÃ³n durante entrenamiento



### Si el modelo no converge**Sin necesidad de:**

- Abrir terminales adicionales

```yaml- Ejecutar comandos TensorBoard manualmente

learning_rate: 5e-3  # Aumentar- Cambiar entre ventanas

dropout: 0.2         # Reducir

hidden_dim: 128      # Aumentar capacidad**Todo en una sola interfaz web integrada.**

```

### Dos Modelos para Comparar

### Si hay overfitting (train_acc >> val_acc)

1. **VAE EstÃ¡ndar (Mean Pooling)**:

```yaml   - Agrega mÃºltiples mediciones por participante

dropout: 0.4-0.5     # Aumentar regularizaciÃ³n   - ~6,700 parÃ¡metros

hidden_dim: 32       # Reducir capacidad   - Entrenamiento rÃ¡pido (~2-5 min)

num_layers: 1        # Simplificar arquitectura   - Baseline sÃ³lido

val_split: 0.3       # MÃ¡s datos de validaciÃ³n

```2. **LSTM-VAE (Sequences)**:

   - Preserva variabilidad intra-participante

### Si hay underfitting (ambos accuracy bajos)   - ~205,850 parÃ¡metros

   - Entrenamiento mÃ¡s lento (~5-15 min)

```yaml   - Captura patrones temporales/secuenciales

hidden_dim: 128-256  # Aumentar capacidad

num_layers: 3        # MÃ¡s profundidad**Pregunta de InvestigaciÃ³n**: Â¿La variabilidad intra-participante mejora la clasificaciÃ³n CT vs ELA?

dropout: 0.2         # Menos regularizaciÃ³n

max_epochs: 100-200  # MÃ¡s tiempo de entrenamiento## ğŸ› ï¸ TecnologÃ­as Utilizadas

```

- **Python 3.8+**: Lenguaje base

## ğŸ› Troubleshooting- **Streamlit**: Framework para la aplicaciÃ³n web interactiva

- **PyTorch**: Framework de deep learning

**Error: Module not found**- **PyTorch Lightning**: Wrapper para simplificar entrenamiento y logging

```bash- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento (integrado con Lightning)

pip install -r requirements.txt- **Pandas & NumPy**: ManipulaciÃ³n de datos

```- **Scikit-learn**: PCA, normalizaciÃ³n, mÃ©tricas

- **Plotly & Seaborn**: Visualizaciones interactivas y estÃ¡ticas

**CUDA out of memory**- **Matplotlib**: GrÃ¡ficos complementarios

```python

# En train_classifier.py, reducir batch_size## ğŸ“Š Dataset

batch_size: 8  # o 4

```- **Formato**: CSV

- **Filas**: Observaciones de mitocondrias individuales

**Model not converging**- **Columnas**: 12 (mÃ©tricas morfolÃ³gicas + variables demogrÃ¡ficas)

- Aumentar learning_rate a 5e-3- **Grupos**: CT (Control) y ELA (Esclerosis Lateral AmiotrÃ³fica)

- Reducir dropout a 0.2

- Aumentar max_epochs a 100-200## ğŸ” Preguntas de InvestigaciÃ³n



**High variance across folds**1. Â¿Existen diferencias morfolÃ³gicas significativas entre grupos CT y ELA?

- Normal con N=202. Â¿Las mÃ©tricas de superficie, volumen y longitud estÃ¡n correlacionadas?

- Probar diferentes random_state3. Â¿El PCA revela separaciÃ³n natural entre grupos?

- Aumentar early_stopping_patience4. Â¿El autoencoder captura patrones no lineales que el PCA no detecta?

- Considerar feature engineering5. Â¿Hay clusterizaciÃ³n por participante o caracterÃ­sticas demogrÃ¡ficas?

6. **Â¿La variabilidad intra-participante (LSTM-VAE) mejora la clasificaciÃ³n vs mean pooling (VAE estÃ¡ndar)?** â­

**Puerto 8501 ocupado**

```bash## ğŸ“š DocumentaciÃ³n Adicional

streamlit run app.py --server.port 8502

```- **`LSTM_VAE_ARCHITECTURE.md`**: GuÃ­a tÃ©cnica detallada de la arquitectura LSTM-VAE

- **`docs/TRAINING_GUIDE.md`**: GuÃ­a completa de entrenamiento con TensorBoard

## ğŸ“ PrÃ³ximos Pasos- **`TENSORBOARD_INTEGRATION_SUMMARY.md`**: Resumen de integraciÃ³n y caracterÃ­sticas

- **`test_lstm_vae.py`**: Script de validaciÃ³n de la implementaciÃ³n LSTM-VAE

1. **Feature Engineering**: Explorar ratios, combinaciones no lineales- **`test_tensorboard_integration.py`**: Test de integraciÃ³n de TensorBoard

2. **Ensemble**: Promediar predicciones de los K modelos

3. **Interpretabilidad**: SHAP values, attention weights## ğŸ¤ Contribuciones

4. **MÃ¡s datos**: Si es posible, aumentar N participantes

5. **Transfer learning**: Pre-entrenar en datasets similaresEste es un proyecto de investigaciÃ³n. Las sugerencias y mejoras son bienvenidas.



---## ğŸ“ Licencia



**Ãšltima actualizaciÃ³n**: Noviembre 2025[Especificar licencia si aplica]


## ğŸ‘¤ Autor

Daniel - AnÃ¡lisis de morfologÃ­a mitocondrial

---

**Nota**: Este proyecto utiliza PyTorch Lightning para el entrenamiento del autoencoder, con **TensorBoard embebido en Streamlit** para monitorear mÃ©tricas en tiempo real. La integraciÃ³n completa permite entrenar, monitorear y visualizar modelos sin salir del navegador.

## ğŸ¯ Inicio RÃ¡pido

```bash
# 1. Clonar repositorio
git clone https://github.com/DanZangrando/mitochondrial-morphology.git
cd mitochondrial-morphology

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Ejecutar aplicaciÃ³n
streamlit run app.py

# 4. Entrenar modelo
# Ir a pÃ¡gina "ğŸ“ Entrenar Modelo" en el navegador
# Seleccionar tipo de modelo y configurar hiperparÃ¡metros
# Click en "ğŸš€ Iniciar Entrenamiento"
# TensorBoard se abre automÃ¡ticamente mostrando mÃ©tricas en tiempo real

# 5. Visualizar resultados
# Ir a pÃ¡gina "ğŸ¤– Autoencoder"
# Cargar modelo entrenado
# Explorar espacio latente y mÃ©tricas
```
