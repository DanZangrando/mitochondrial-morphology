# AnÃ¡lisis de MorfologÃ­a Mitocondrial

## ğŸ“Š DescripciÃ³n del Proyecto

Este proyecto analiza mÃ©tricas morfolÃ³gicas de mitocondrias para identificar patrones y diferencias entre grupos de estudio (Control vs ELA). Utilizamos tÃ©cnicas de anÃ¡lisis exploratorio, reducciÃ³n dimensional (PCA) y deep learning (Autoencoder) para visualizar el espacio latente y detectar posibles clusterizaciones.

### MÃ©tricas Analizadas

Los datos contienen las siguientes mÃ©tricas por mitocondria:

- **N mitocondrias**: NÃºmero de mitocondrias analizadas
- **IsoVol (SUMA/PROM)**: Volumen isomÃ©trico total y promedio
- **Surface (SUMA/PROM)**: Superficie total y promedio
- **Length (SUMA/PROM)**: Longitud total y promedio
- **RoughSph (SUMA/PROM)**: Ãndice de rugosidad/esfericidad total y promedio
- **Variables demogrÃ¡ficas**: Age, Sex, Group (CT/ELA), Participant

## ğŸ¯ Objetivos

1. **AnÃ¡lisis Exploratorio**: Examinar distribuciones y diferencias entre grupos (CT vs ELA), sexos y participantes
2. **PCA (AnÃ¡lisis de Componentes Principales)**: Reducir dimensionalidad y visualizar la varianza explicada
3. **Autoencoder**: Entrenar una red neuronal para comprimir la informaciÃ³n y explorar el espacio latente
4. **VisualizaciÃ³n**: Identificar si existe clusterizaciÃ³n natural de los datos segÃºn caracterÃ­sticas morfolÃ³gicas

## ğŸ—ï¸ Estructura del Proyecto

```
mitochondrial-morphology/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data.csv                    # Dataset original
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py              # Carga y preprocesamiento de datos
â”‚   â”œâ”€â”€ pca_analysis.py             # ImplementaciÃ³n del PCA
â”‚   â”œâ”€â”€ autoencoder.py              # Arquitectura del Autoencoder (PyTorch Lightning)
â”‚   â””â”€â”€ utils.py                    # Funciones auxiliares y visualizaciÃ³n
â”‚
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_ğŸ“Š_EDA.py                 # PÃ¡gina de AnÃ¡lisis Exploratorio
â”‚   â”œâ”€â”€ 2_ğŸ¯_PCA.py                 # PÃ¡gina de AnÃ¡lisis PCA
â”‚   â””â”€â”€ 3_ğŸ¤–_Autoencoder.py         # PÃ¡gina de Entrenamiento y VisualizaciÃ³n
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train_autoencoder.py        # Script para entrenar el autoencoder
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ .gitkeep                    # Modelos entrenados guardados aquÃ­
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ .gitkeep                    # Logs de TensorBoard (Lightning)
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                 # ConfiguraciÃ³n del proyecto
â”‚
â”œâ”€â”€ app.py                          # AplicaciÃ³n Streamlit principal (home)
â”œâ”€â”€ requirements.txt                # Dependencias del proyecto
â”œâ”€â”€ .gitignore                      # Archivos a ignorar en Git
â””â”€â”€ README.md                       # Este archivo
```

### JustificaciÃ³n de la Estructura

- **`src/`**: MÃ³dulos reutilizables para anÃ¡lisis y modelado (backend lÃ³gico)
- **`pages/`**: PÃ¡ginas de Streamlit - arquitectura multi-page nativa de Streamlit
- **`scripts/`**: Scripts Python ejecutables (ej: entrenamiento del autoencoder)
- **`models/`**: Checkpoints del autoencoder entrenado (generados por PyTorch Lightning)
- **`logs/`**: Logs de TensorBoard generados automÃ¡ticamente por PyTorch Lightning
- **`config/`**: Archivo YAML centralizado con todos los parÃ¡metros del proyecto
- **`app.py`**: PÃ¡gina principal de Streamlit (home), punto de entrada de la aplicaciÃ³n

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos

- Python 3.8+
- pip o conda

### 1. Clonar el Repositorio

```bash
git clone <URL_DEL_REPOSITORIO>
cd mitochondrial-morphology
```

### 2. Crear Entorno Virtual (Recomendado)

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Ejecutar la AplicaciÃ³n Streamlit

```bash
streamlit run app.py
```

La aplicaciÃ³n se abrirÃ¡ en tu navegador (por defecto: `http://localhost:8501`)

**NavegaciÃ³n**: La aplicaciÃ³n usa la arquitectura multi-page de Streamlit:
- **Home (app.py)**: PÃ¡gina principal con descripciÃ³n del proyecto
- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo
- **ğŸ¯ PCA**: VisualizaciÃ³n de componentes principales  
- **ğŸ¤– Autoencoder**: Entrenamiento y exploraciÃ³n del espacio latente

### 5. Entrenar el Autoencoder

Puedes entrenar el autoencoder de dos formas:

**OpciÃ³n A - Desde la interfaz web**:
1. Ejecuta la app: `streamlit run app.py`
2. Ve a la pÃ¡gina "ğŸ¤– Autoencoder"
3. Haz clic en "ğŸš€ Entrenar Autoencoder"

**OpciÃ³n B - Desde la terminal**:
```bash
python scripts/train_autoencoder.py
```

### 5. Ver Logs de TensorBoard (Opcional)

Durante el entrenamiento del autoencoder, PyTorch Lightning genera logs automÃ¡ticamente. 
Para visualizarlos en tiempo real:

```bash
tensorboard --logdir=logs/
```

Abre tu navegador en `http://localhost:6006` para ver mÃ©tricas de entrenamiento, grÃ¡ficos de pÃ©rdida, y mÃ¡s.

## ğŸ“ˆ Estrategia de AnÃ¡lisis

### Fase 1: AnÃ¡lisis Exploratorio de Datos (EDA)

**Objetivo**: Comprender la distribuciÃ³n y relaciones de las mÃ©tricas

**TÃ©cnicas**:
- EstadÃ­sticas descriptivas por grupo (CT vs ELA)
- Visualizaciones:
  - Distribuciones (histogramas, boxplots) por grupo y sexo
  - Matrices de correlaciÃ³n
  - Pairplots para variables clave
- Pruebas estadÃ­sticas (t-test, ANOVA) para diferencias entre grupos

**Herramientas**: Pandas, Seaborn, Plotly (para interactividad en Streamlit)

### Fase 2: PCA (ReducciÃ³n Dimensional)

**Objetivo**: Identificar las componentes principales que explican la mayor varianza

**Proceso**:
1. NormalizaciÃ³n de features (StandardScaler)
2. Aplicar PCA y visualizar varianza explicada (scree plot)
3. Proyectar datos en 2D/3D (PC1 vs PC2 vs PC3)
4. Colorear por grupo, sexo y participante para identificar patrones

**InterpretaciÃ³n**: 
- Â¿Se separan los grupos CT y ELA en el espacio PCA?
- Â¿QuÃ© mÃ©tricas contribuyen mÃ¡s a cada componente?

### Fase 3: Autoencoder con PyTorch Lightning

**Objetivo**: Aprender una representaciÃ³n comprimida del espacio latente

**Arquitectura Propuesta**:
```
Input (8 features) â†’ Encoder (Dense layers) â†’ Latent Space (2-3D) â†’ Decoder â†’ Output (8 features)
```

**ConfiguraciÃ³n**:
- **Framework**: PyTorch Lightning (simplifica entrenamiento, logging automÃ¡tico)
- **Loss**: MSE (Mean Squared Error) para reconstrucciÃ³n
- **Optimizer**: Adam
- **Logging**: TensorBoard nativo de Lightning (`TensorBoardLogger`)
- **Callbacks**: Early Stopping, ModelCheckpoint

**VisualizaciÃ³n**:
- ProyecciÃ³n del espacio latente en 2D/3D
- Comparar con PCA: Â¿El autoencoder captura estructura no lineal?
- Visualizar reconstrucciones vs datos originales

### Fase 4: IntegraciÃ³n en Streamlit

**Arquitectura Multi-Page de Streamlit**:

La aplicaciÃ³n utiliza la estructura nativa de mÃºltiples pÃ¡ginas de Streamlit:

1. **Home (app.py)**: 
   - DescripciÃ³n del proyecto y dataset
   - MÃ©tricas generales
   - Vista previa de los datos

2. **ğŸ“Š EDA (pages/1_ğŸ“Š_EDA.py)**:
   - SelecciÃ³n interactiva de mÃ©tricas y grupos
   - GrÃ¡ficos de distribuciÃ³n (box, violin, histogram)
   - Matriz de correlaciÃ³n interactiva
   - Pruebas estadÃ­sticas automÃ¡ticas (t-test/ANOVA)
   - Scatter plot matrix
   - AnÃ¡lisis por edad y participante

3. **ğŸ¯ PCA (pages/2_ğŸ¯_PCA.py)**:
   - ConfiguraciÃ³n dinÃ¡mica del nÃºmero de componentes
   - Scree plot de varianza explicada
   - Proyecciones 2D y 3D interactivas (Plotly)
   - AnÃ¡lisis de loadings (contribuciÃ³n de variables)
   - ColorizaciÃ³n por grupo/sexo/participante
   - ExportaciÃ³n de resultados

4. **ğŸ¤– Autoencoder (pages/3_ğŸ¤–_Autoencoder.py)**:
   - Interfaz para entrenar el modelo desde la web
   - VisualizaciÃ³n del espacio latente 2D/3D
   - ComparaciÃ³n de reconstrucciones
   - MÃ©tricas de error (MSE, MAE, RMSE)
   - ComparaciÃ³n conceptual con PCA
   - ExportaciÃ³n del espacio latente
   - Instrucciones para TensorBoard

**Ventajas de esta arquitectura**:
- âœ… Todo nativo en Streamlit (sin necesidad de frameworks adicionales)
- âœ… NavegaciÃ³n automÃ¡tica mediante sidebar
- âœ… Cache de datos para mejor rendimiento
- âœ… Visualizaciones interactivas con Plotly
- âœ… Entrenamiento del modelo integrado en la UI
- âœ… Logs nativos de PyTorch Lightning visibles en TensorBoard

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.8+**: Lenguaje base
- **Streamlit**: Framework para la aplicaciÃ³n web interactiva
- **PyTorch**: Framework de deep learning
- **PyTorch Lightning**: Wrapper para simplificar entrenamiento y logging
- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento (integrado con Lightning)
- **Pandas & NumPy**: ManipulaciÃ³n de datos
- **Scikit-learn**: PCA, normalizaciÃ³n, mÃ©tricas
- **Plotly & Seaborn**: Visualizaciones interactivas y estÃ¡ticas
- **Matplotlib**: GrÃ¡ficos complementarios

## ğŸ“Š Dataset

- **Formato**: CSV
- **Filas**: Observaciones de mitocondrias individuales
- **Columnas**: 12 (mÃ©tricas morfolÃ³gicas + variables demogrÃ¡ficas)
- **Grupos**: CT (Control) y ELA (Esclerosis Lateral AmiotrÃ³fica)

## ğŸ” Preguntas de InvestigaciÃ³n

1. Â¿Existen diferencias morfolÃ³gicas significativas entre grupos CT y ELA?
2. Â¿Las mÃ©tricas de superficie, volumen y longitud estÃ¡n correlacionadas?
3. Â¿El PCA revela separaciÃ³n natural entre grupos?
4. Â¿El autoencoder captura patrones no lineales que el PCA no detecta?
5. Â¿Hay clusterizaciÃ³n por participante o caracterÃ­sticas demogrÃ¡ficas?

## ğŸ¤ Contribuciones

Este es un proyecto de investigaciÃ³n. Las sugerencias y mejoras son bienvenidas.

## ğŸ“ Licencia

[Especificar licencia si aplica]

## ğŸ‘¤ Autor

Daniel - AnÃ¡lisis de morfologÃ­a mitocondrial

---

**Nota**: Este proyecto utiliza PyTorch Lightning para el entrenamiento del autoencoder, lo que permite una integraciÃ³n nativa con TensorBoard para monitorear mÃ©tricas en tiempo real, que luego se visualizan directamente en la aplicaciÃ³n Streamlit.
