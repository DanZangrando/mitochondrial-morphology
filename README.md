# AnÃ¡lisis de MorfologÃ­a Mitocondrial - CT vs ELA# AnÃ¡lisis de MorfologÃ­a Mitocondrial - CT vs ELA# AnÃ¡lisis de MorfologÃ­a Mitocondrial



## ğŸ“Š DescripciÃ³n del Proyecto



Proyecto de clasificaciÃ³n supervisada que utiliza **deep learning con LSTM** para distinguir participantes Control (CT) vs Esclerosis Lateral AmiotrÃ³fica (ELA) basÃ¡ndose en mÃ©tricas morfolÃ³gicas mitocondriales.## ğŸ“Š DescripciÃ³n del Proyecto## ğŸ“Š DescripciÃ³n del Proyecto



**CaracterÃ­sticas principales:**



- **Dataset pequeÃ±o**: 20 participantes (10 CT, 10 ELA) con secuencias de longitud variable (4-36 mediciones)Proyecto de clasificaciÃ³n supervisada que utiliza **deep learning con LSTM** para distinguir participantes Control (CT) vs Esclerosis Lateral AmiotrÃ³fica (ELA) basÃ¡ndose en mÃ©tricas morfolÃ³gicas mitocondriales.Este proyecto analiza mÃ©tricas morfolÃ³gicas de mitocondrias para identificar patrones y diferencias entre grupos de estudio (Control vs ELA). Utilizamos tÃ©cnicas de anÃ¡lisis exploratorio, reducciÃ³n dimensional (PCA) y deep learning (Autoencoder) para visualizar el espacio latente y detectar posibles clusterizaciones.

- **Train/Val Split Estratificado**: DivisiÃ³n 80/20 con stratification para balance de clases

- **LSTM Bidireccional**: Captura patrones en secuencias de mediciones

- **ClasificaciÃ³n binaria**: CT (clase 0) vs ELA (clase 1)

- **EvaluaciÃ³n con Significancia EstadÃ­stica**: Matrices de confusiÃ³n modernas con p-value (test binomial)**CaracterÃ­sticas principales:**### MÃ©tricas Analizadas



### ğŸ“ MÃ©tricas MorfolÃ³gicas Analizadas- **Dataset pequeÃ±o**: 20 participantes (10 CT, 10 ELA) con secuencias de longitud variable (4-36 mediciones)



**8 features de entrada** (todas agregadas SUMA/PROM por mitocondria):- **K-Fold Cross-Validation**: Entrenamiento robusto con validaciÃ³n cruzada estratificadaLos datos contienen las siguientes mÃ©tricas por mitocondria:



- **IsoVol**: Volumen isomÃ©trico- **LSTM Bidireccional**: Captura patrones en secuencias de mediciones

- **Surface**: Ãrea de superficie

- **Length**: Longitud- **ClasificaciÃ³n binaria**: CT (clase 0) vs ELA (clase 1)- **N mitocondrias**: NÃºmero de mitocondrias analizadas

- **RoughSph**: Ãndice de rugosidad/esfericidad

- **IsoVol (SUMA/PROM)**: Volumen isomÃ©trico total y promedio

**Variables demogrÃ¡ficas** (NO usadas como input del modelo):

### ğŸ“ MÃ©tricas MorfolÃ³gicas Analizadas- **Surface (SUMA/PROM)**: Superficie total y promedio

- Age, Sex, Group (CT/ELA), Participant, n_mitochondrias

- **Length (SUMA/PROM)**: Longitud total y promedio

## ğŸ¯ Objetivos

**8 features de entrada** (todas agregadas SUMA/PROM por mitocondria):- **RoughSph (SUMA/PROM)**: Ãndice de rugosidad/esfericidad total y promedio

1. **ClasificaciÃ³n Supervisada**: Predecir correctamente participantes CT vs ELA usando solo morfologÃ­a mitocondrial

2. **AnÃ¡lisis Exploratorio**: Examinar distribuciones y diferencias entre grupos- **IsoVol**: Volumen isomÃ©trico- **Variables demogrÃ¡ficas**: Age, Sex, Group (CT/ELA), Participant

3. **ReducciÃ³n Dimensional**: Visualizar patrones con PCA (lineal) y explorar separabilidad

4. **Significancia EstadÃ­stica**: Validar resultados con test binomial (vs random baseline 50%)- **Surface**: Ãrea de superficie



## ğŸ—ï¸ Estructura del Proyecto- **Length**: Longitud## ğŸ¯ Objetivos



```- **RoughSph**: Ãndice de rugosidad/esfericidad

mitochondrial-morphology/

â”‚1. **AnÃ¡lisis Exploratorio**: Examinar distribuciones y diferencias entre grupos (CT vs ELA), sexos y participantes

â”œâ”€â”€ data/

â”‚   â””â”€â”€ data.csv                    # Dataset (306 muestras, 20 participantes)**Variables demogrÃ¡ficas** (NO usadas como input del modelo):2. **PCA (AnÃ¡lisis de Componentes Principales)**: Reducir dimensionalidad y visualizar la varianza explicada

â”‚

â”œâ”€â”€ src/- Age, Sex, Group (CT/ELA), Participant, n_mitochondrias3. **Autoencoder**: Entrenar una red neuronal para comprimir la informaciÃ³n y explorar el espacio latente

â”‚   â”œâ”€â”€ __init__.py

â”‚   â”œâ”€â”€ data_loader.py              # Carga y preprocesamiento4. **VisualizaciÃ³n**: Identificar si existe clusterizaciÃ³n natural de los datos segÃºn caracterÃ­sticas morfolÃ³gicas

â”‚   â”œâ”€â”€ classifier.py               # LSTM Classifier (PyTorch Lightning)

â”‚   â””â”€â”€ utils.py                    # Funciones auxiliares## ğŸ¯ Objetivos

â”‚

â”œâ”€â”€ pages/## ğŸ—ï¸ Estructura del Proyecto

â”‚   â”œâ”€â”€ 1_ğŸ“Š_EDA.py                 # AnÃ¡lisis Exploratorio

â”‚   â”œâ”€â”€ 2_ğŸ¯_PCA.py                 # PCA (participante + individual)1. **ClasificaciÃ³n Supervisada**: Predecir correctamente participantes CT vs ELA usando solo morfologÃ­a mitocondrial

â”‚   â””â”€â”€ 3_ğŸ¯_Entrenar_Clasificador.py  # Entrenamiento + EvaluaciÃ³n integrada

â”‚2. **AnÃ¡lisis Exploratorio**: Examinar distribuciones y diferencias entre grupos```

â”œâ”€â”€ scripts/

â”‚   â””â”€â”€ train_classifier.py         # Script de entrenamiento (CLI)3. **ReducciÃ³n Dimensional**: Visualizar patrones con PCA (lineal) y explorar separabilidadmitochondrial-morphology/

â”‚

â”œâ”€â”€ models/4. **K-Fold Cross-Validation**: Obtener mÃ©tricas robustas (mean Â± std) para datasets pequeÃ±osâ”‚

â”‚   â”œâ”€â”€ *.ckpt                      # Modelos entrenados

â”‚   â””â”€â”€ *_metadata.json             # Metadata con info de train/val participantsâ”œâ”€â”€ data/

â”‚

â”œâ”€â”€ logs/## ğŸ—ï¸ Estructura del Proyectoâ”‚   â””â”€â”€ data.csv                    # Dataset original

â”‚   â””â”€â”€ lstm_classifier/            # TensorBoard logs

â”‚â”‚

â”œâ”€â”€ config/

â”‚   â””â”€â”€ config.yaml                 # ConfiguraciÃ³n del proyecto```â”œâ”€â”€ src/

â”‚

â”œâ”€â”€ app.py                          # Punto de entrada Streamlitmitochondrial-morphology/â”‚   â”œâ”€â”€ __init__.py

â”œâ”€â”€ README.md                       # Este archivo

â””â”€â”€ requirements.txt                # Dependencias Pythonâ”‚â”‚   â”œâ”€â”€ data_loader.py              # Carga y preprocesamiento de datos

```

â”œâ”€â”€ data/â”‚   â”œâ”€â”€ pca_analysis.py             # ImplementaciÃ³n del PCA

## ğŸš€ InstalaciÃ³n y Uso

â”‚   â””â”€â”€ data.csv                    # Dataset (306 muestras, 20 participantes)â”‚   â”œâ”€â”€ autoencoder.py              # Arquitectura del Autoencoder (PyTorch Lightning)

### Prerrequisitos

â”‚â”‚   â””â”€â”€ utils.py                    # Funciones auxiliares y visualizaciÃ³n

- Python 3.8+

- pip o condaâ”œâ”€â”€ src/â”‚



### 1. Clonar el Repositorioâ”‚   â”œâ”€â”€ __init__.pyâ”œâ”€â”€ pages/



```bashâ”‚   â”œâ”€â”€ data_loader.py              # Carga y preprocesamientoâ”‚   â”œâ”€â”€ 1_ğŸ“Š_EDA.py                 # PÃ¡gina de AnÃ¡lisis Exploratorio

git clone https://github.com/DanZangrando/mitochondrial-morphology.git

cd mitochondrial-morphologyâ”‚   â”œâ”€â”€ pca_analysis.py             # AnÃ¡lisis PCAâ”‚   â”œâ”€â”€ 2_ï¿½_Entrenar_Modelo.py     # PÃ¡gina de Entrenamiento con TensorBoard

```

â”‚   â”œâ”€â”€ classifier.py               # LSTM Classifier (PyTorch Lightning)â”‚   â””â”€â”€ 3_ğŸ¤–_Autoencoder.py         # PÃ¡gina de VisualizaciÃ³n de Modelos

### 2. Crear Entorno Virtual (Recomendado)

â”‚   â””â”€â”€ utils.py                    # Funciones auxiliaresâ”‚

```bash

python -m venv venvâ”‚â”œâ”€â”€ scripts/

source venv/bin/activate  # En Windows: venv\Scripts\activate

```â”œâ”€â”€ pages/â”‚   â””â”€â”€ train_autoencoder.py        # Script para entrenar el autoencoder



### 3. Instalar Dependenciasâ”‚   â”œâ”€â”€ 1_ğŸ“Š_EDA.py                 # AnÃ¡lisis Exploratorioâ”‚



```bashâ”‚   â”œâ”€â”€ 2_ğŸ¯_PCA.py                 # PCA (participante + individual)â”œâ”€â”€ models/

pip install -r requirements.txt

```â”‚   â”œâ”€â”€ 3_ğŸ“_Entrenar_Modelo.py     # Entrenamiento (simple split o K-Fold)â”‚   â””â”€â”€ .gitkeep                    # Modelos entrenados guardados aquÃ­



### 4. Ejecutar la AplicaciÃ³n Streamlitâ”‚   â””â”€â”€ 4_ğŸ¤–_Clasificador.py        # VisualizaciÃ³n de resultadosâ”‚



```bashâ”‚â”œâ”€â”€ logs/

streamlit run app.py

```â”œâ”€â”€ scripts/â”‚   â””â”€â”€ .gitkeep                    # Logs de TensorBoard (Lightning)



La aplicaciÃ³n se abrirÃ¡ en tu navegador (por defecto: `http://localhost:8501`)â”‚   â””â”€â”€ train_classifier.py         # Script de entrenamiento (CLI)â”‚



**NavegaciÃ³n**: La aplicaciÃ³n usa la arquitectura multi-page de Streamlit:â”‚â”œâ”€â”€ config/



- **Home (app.py)**: PÃ¡gina principal con descripciÃ³n del proyectoâ”œâ”€â”€ models/â”‚   â””â”€â”€ config.yaml                 # ConfiguraciÃ³n del proyecto

- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo

- **ğŸ¯ PCA**: ReducciÃ³n dimensional con visualizaciÃ³n 2D/3Dâ”‚   â”œâ”€â”€ *.ckpt                      # Modelos entrenados (simple split)â”‚

- **ğŸ¯ Entrenar Clasificador**: Entrenamiento + EvaluaciÃ³n integrada con matrices modernas

â”‚   â””â”€â”€ kfold_K/                    # Modelos K-Fold + summary.jsonâ”œâ”€â”€ app.py                          # AplicaciÃ³n Streamlit principal (home)

## ğŸ§  Arquitectura del Modelo

â”‚â”œâ”€â”€ requirements.txt                # Dependencias del proyecto

### LSTM Classifier

â”œâ”€â”€ logs/â”œâ”€â”€ .gitignore                      # Archivos a ignorar en Git

```

Input: (batch, seq_len, 8)  [8 features morfomÃ©tricas]â”‚   â””â”€â”€ lstm_classifier/            # TensorBoard logsâ””â”€â”€ README.md                       # Este archivo

           â†“

Bidirectional LSTM (2 layers, hidden_dim=64)â”‚```

           â†“

Concatenate [forward_hidden, backward_hidden]â”œâ”€â”€ config/

           â†“

Fully Connected: 128 â†’ ReLU â†’ Dropout(0.3)â”‚   â””â”€â”€ config.yaml                 # ConfiguraciÃ³n del proyecto### JustificaciÃ³n de la Estructura

           â†“

Fully Connected: 64 â†’ ReLU â†’ Dropout(0.3)â”‚

           â†“

Fully Connected: 32 â†’ ReLU â†’ Dropout(0.3)â”œâ”€â”€ app.py                          # Punto de entrada Streamlit- **`src/`**: MÃ³dulos reutilizables para anÃ¡lisis y modelado (backend lÃ³gico)

           â†“

Output: (batch, 2)  [logits para CT/ELA]â”œâ”€â”€ README.md                       # Este archivo- **`pages/`**: PÃ¡ginas de Streamlit - arquitectura multi-page nativa de Streamlit

```

â””â”€â”€ requirements.txt                # Dependencias Python- **`scripts/`**: Scripts Python ejecutables (ej: entrenamiento del autoencoder)

**CaracterÃ­sticas:**

```- **`models/`**: Checkpoints del autoencoder entrenado (generados por PyTorch Lightning)

- **Input variable**: Acepta secuencias de longitud variable (4-36 mediciones/participante)

- **Bidireccional**: Captura patrones en ambas direcciones- **`logs/`**: Logs de TensorBoard generados automÃ¡ticamente por PyTorch Lightning

- **RegularizaciÃ³n**: Dropout para prevenir overfitting

- **Loss**: Cross Entropy## ğŸš€ Quick Start- **`config/`**: Archivo YAML centralizado con todos los parÃ¡metros del proyecto

- **Optimizer**: Adam con learning rate scheduler (ReduceLROnPlateau)

- **ParÃ¡metros**: ~147K trainable params- **`app.py`**: PÃ¡gina principal de Streamlit (home), punto de entrada de la aplicaciÃ³n



## ğŸ“Š Dataset### 1. Instalar dependencias



- **Total muestras**: 306 mediciones```bash## ğŸš€ InstalaciÃ³n y Uso

- **Participantes**: 20 (10 CT, 10 ELA)

- **DistribuciÃ³n por grupo**:# Crear entorno virtual (recomendado)

  - CT: 167 samples, 10 participants

  - ELA: 139 samples, 10 participantspython -m venv venv### Prerrequisitos

- **Secuencias**: Longitud variable por participante (min: 4, max: 36)

- **Features**: 8 mÃ©tricas morfolÃ³gicas (IsoVol, Surface, Length, RoughSph - SUMA/PROM)source venv/bin/activate  # Linux/Mac



## ğŸ“ Entrenamiento# venv\Scripts\activate  # Windows- Python 3.8+



### OpciÃ³n 1: Desde Streamlit (Recomendado)- pip o conda



1. Ejecutar `streamlit run app.py`# Instalar dependencias

2. Ir a pÃ¡gina **ğŸ¯ Entrenar Clasificador**

3. Configurar hiperparÃ¡metros en sidebarpip install -r requirements.txt### 1. Clonar el Repositorio

4. Click en **ğŸš€ Iniciar Entrenamiento**

5. Ver resultados inmediatamente en la misma pÃ¡gina```



### OpciÃ³n 2: Desde terminal```bash



```bash### 2. Ejecutar la aplicaciÃ³ngit clone <URL_DEL_REPOSITORIO>

# Entrenamiento con train/val split

python scripts/train_classifier.py```bashcd mitochondrial-morphology



# Ver mÃ©tricas con TensorBoardstreamlit run app.py```

tensorboard --logdir logs/lstm_classifier

``````



## ğŸ“ˆ EvaluaciÃ³n y Significancia EstadÃ­stica### 2. Crear Entorno Virtual (Recomendado)



### Doble EvaluaciÃ³nLa aplicaciÃ³n se abrirÃ¡ en `http://localhost:8501`



La pÃ¡gina de evaluaciÃ³n muestra **dos matrices de confusiÃ³n**:```bash



1. **Matriz de ValidaciÃ³n** (azul):### 3. NavegaciÃ³npython -m venv venv

   - Solo participantes de validaciÃ³n

   - MÃ©tricas reales de generalizaciÃ³nsource venv/bin/activate  # En Windows: venv\Scripts\activate

   - **Incluye p-value** del test binomial

   **PÃ¡ginas disponibles:**```

2. **Matriz de Dataset Completo** (verde):

   - Todos los participantes (train + val)

   - Solo referencia, no para evaluar

1. **ğŸ“Š EDA (AnÃ¡lisis Exploratorio)**### 3. Instalar Dependencias

### P-Value y Significancia

   - EstadÃ­sticas descriptivas

El **test binomial** evalÃºa si la accuracy es significativamente mejor que el azar (50%):

   - Distribuciones por grupo (CT vs ELA)```bash

- **Hâ‚€**: accuracy = 0.5 (clasificaciÃ³n aleatoria)

- **Hâ‚**: accuracy > 0.5 (el modelo aprende)   - Correlaciones entre variablespip install -r requirements.txt



**InterpretaciÃ³n**:   - AnÃ¡lisis por participante```



| Significancia | InterpretaciÃ³n | SÃ­mbolo |

|--------------|----------------|---------|

| p < 0.001 | Altamente significativo | *** |2. **ğŸ¯ PCA (AnÃ¡lisis de Componentes Principales)**### 4. Ejecutar la AplicaciÃ³n Streamlit

| p < 0.01 | Muy significativo | ** |

| p < 0.05 | Significativo | * |   - PCA a nivel participante (agregado por participant)

| p â‰¥ 0.05 | No significativo | ns |

   - PCA a nivel individual (todas las mediciones)```bash

**Ejemplo**: Con 8/10 participantes correctos (80% accuracy), p â‰ˆ 0.055 (borderline)

   - VisualizaciÃ³n 2D/3D interactivastreamlit run app.py

### VisualizaciÃ³n Moderna

   - Varianza explicada```

Las matrices de confusiÃ³n incluyen:



- âœ… Gradientes de color personalizados (azul/verde)

- âœ… NÃºmeros absolutos + porcentajes3. **ğŸ“ Entrenar Modelo**La aplicaciÃ³n se abrirÃ¡ en tu navegador (por defecto: `http://localhost:8501`)

- âœ… Hover interactivo con detalles

- âœ… Colorbar con escala   - **Train/Val Split Simple** (80/20)

- âœ… P-value en tÃ­tulo (matriz de validaciÃ³n)

- âœ… InterpretaciÃ³n estadÃ­stica automÃ¡tica   - **K-Fold Cross-Validation** (K=3-10, recomendado K=5)**NavegaciÃ³n**: La aplicaciÃ³n usa la arquitectura multi-page de Streamlit:



## ğŸ—‚ï¸ Metadata de Entrenamiento   - ConfiguraciÃ³n de hiperparÃ¡metros:- **Home (app.py)**: PÃ¡gina principal con descripciÃ³n del proyecto



Cada modelo entrenado guarda dos archivos:     - Max epochs, batch size, learning rate- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo



1. **Checkpoint (.ckpt)**: Pesos del modelo     - Hidden dim, num layers, dropout- **ï¿½ Entrenar Modelo**: Entrenar VAE/LSTM-VAE con TensorBoard en tiempo real

2. **Metadata JSON**: InformaciÃ³n del entrenamiento

   ```json     - Early stopping, checkpointing- **ğŸ¤– Autoencoder**: VisualizaciÃ³n del espacio latente y mÃ©tricas

   {

     "train_participants": [1, 2, 3, ...],   - Resultados en tiempo real

     "val_participants": [18, 19, 20],

     "val_split": 0.2,### 5. Entrenar el Autoencoder

     "random_state": 42,

     "best_model_path": "...",4. **ğŸ¤– Clasificador (Resultados)**

     "best_score": 0.85,

     "hyperparameters": {...}   - Accuracy, confusion matrixPuedes entrenar el autoencoder de dos formas:

   }

   ```   - Classification report (precision, recall, F1)



Esto permite **reproducir exactamente** quÃ© participantes se usaron en train/val.   - DistribuciÃ³n de probabilidades**OpciÃ³n A - Desde la interfaz web (Recomendado)**:



## ğŸ“Š InterpretaciÃ³n de Resultados   - AnÃ¡lisis por participante1. Ejecuta la app: `streamlit run app.py`



### Accuracy Guidelines   - MÃ©tricas de entrenamiento (loss, accuracy)2. Ve a la pÃ¡gina "ğŸ“ Entrenar Modelo"



| Accuracy | InterpretaciÃ³n |3. Selecciona el tipo de modelo:

|----------|----------------|

| **>70%** | âœ… Excelente - Hay seÃ±al morfomÃ©trica clara entre CT/ELA |## ğŸ§  Arquitectura del Modelo   - **VAE EstÃ¡ndar**: Agrega mediciones por participante (mean pooling)

| **60-70%** | âš¡ Bueno - Hay separabilidad, puede mejorar con tuning |

| **50-60%** | âš ï¸ Regular - Poco mejor que azar, revisar features |   - **LSTM-VAE**: Preserva variabilidad intra-participante (secuencias completas)

| **<50%** | âŒ Malo - Modelo no estÃ¡ aprendiendo |

### LSTM Classifier4. Configura hiperparÃ¡metros (epochs, learning rate, batch size, patience)

### Outputs guardados

5. Haz clic en "ğŸš€ Iniciar Entrenamiento"

```

models/```6. **TensorBoard se abre automÃ¡ticamente en la misma pÃ¡gina** mostrando mÃ©tricas en tiempo real

â”œâ”€â”€ lstm_classifier-epoch=XX-val_acc=X.XXXX.ckpt

â””â”€â”€ lstm_classifier-epoch=XX-val_acc=X.XXXX_metadata.jsonInput: (batch, seq_len, 8)  [8 features morfomÃ©tricas]



logs/lstm_classifier/           â†“**OpciÃ³n B - Desde la terminal**:

â””â”€â”€ version_0/

    â””â”€â”€ events.out.tfevents...Bidirectional LSTM (2 layers, hidden_dim=64)```bash

```

           â†“# VAE estÃ¡ndar

## ğŸ› ï¸ Stack TecnolÃ³gico

Concatenate [forward_hidden, backward_hidden]python scripts/train_autoencoder.py

| TecnologÃ­a | PropÃ³sito |

|-----------|-----------|           â†“

| **PyTorch** | Deep learning framework |

| **PyTorch Lightning** | Training loop, callbacks, logging |Fully Connected: 128 â†’ ReLU â†’ Dropout(0.3)# LSTM-VAE (preserva variabilidad intra-participante)

| **Streamlit** | Web app interactiva |

| **TensorBoard** | VisualizaciÃ³n de mÃ©tricas |           â†“python scripts/train_autoencoder.py --lstm

| **scikit-learn** | NormalizaciÃ³n, mÃ©tricas, stratification |

| **Plotly** | GrÃ¡ficos interactivos modernos (confusion matrices) |Fully Connected: 64 â†’ ReLU â†’ Dropout(0.3)```

| **Pandas/NumPy** | ManipulaciÃ³n de datos |

| **SciPy** | Test binomial (binomtest) |           â†“



## âš™ï¸ HiperparÃ¡metros RecomendadosFully Connected: 32 â†’ ReLU â†’ Dropout(0.3)### 6. Ver Logs de TensorBoard



### Para empezar (baseline)           â†“



```yamlOutput: (batch, 2)  [logits para CT/ELA]**Durante el entrenamiento desde Streamlit**: TensorBoard se muestra automÃ¡ticamente en un iframe embebido.

hidden_dim: 64

num_layers: 2```

dropout: 0.3

learning_rate: 1e-3**Manualmente** (opcional):

batch_size: 16

max_epochs: 50-100**CaracterÃ­sticas:**```bash

val_split: 0.2

random_state: 42- **Input variable**: Acepta secuencias de longitud variable (4-36 mediciones/participante)tensorboard --logdir=logs/

```

- **Bidireccional**: Captura patrones en ambas direcciones```

### Si el modelo no converge

- **RegularizaciÃ³n**: Dropout para prevenir overfitting

```yaml

learning_rate: 5e-3  # Aumentar- **Loss**: Cross EntropyAbre tu navegador en `http://localhost:6006` para ver mÃ©tricas de entrenamiento, grÃ¡ficos de pÃ©rdida, y mÃ¡s.

dropout: 0.2         # Reducir

hidden_dim: 128      # Aumentar capacidad- **Optimizer**: Adam con learning rate scheduler (ReduceLROnPlateau)

```

- **ParÃ¡metros**: ~147K trainable params## ğŸ“ˆ Estrategia de AnÃ¡lisis

### Si hay overfitting (train_acc >> val_acc)



```yaml

dropout: 0.4-0.5     # Aumentar regularizaciÃ³n## ğŸ“Š Dataset### Fase 1: AnÃ¡lisis Exploratorio de Datos (EDA)

hidden_dim: 32       # Reducir capacidad

num_layers: 1        # Simplificar arquitectura

val_split: 0.3       # MÃ¡s datos de validaciÃ³n

```- **Total muestras**: 306 mediciones**Objetivo**: Comprender la distribuciÃ³n y relaciones de las mÃ©tricas



### Si hay underfitting (ambos accuracy bajos)- **Participantes**: 20 (10 CT, 10 ELA)



```yaml- **DistribuciÃ³n por grupo**:**TÃ©cnicas**:

hidden_dim: 128-256  # Aumentar capacidad

num_layers: 3        # MÃ¡s profundidad  - CT: 167 samples, 10 participants- EstadÃ­sticas descriptivas por grupo (CT vs ELA)

dropout: 0.2         # Menos regularizaciÃ³n

max_epochs: 100-200  # MÃ¡s tiempo de entrenamiento  - ELA: 139 samples, 10 participants- Visualizaciones:

```

- **Secuencias**: Longitud variable por participante (min: 4, max: 36)  - Distribuciones (histogramas, boxplots) por grupo y sexo

## ğŸ› Troubleshooting

- **Features**: 8 mÃ©tricas morfolÃ³gicas (IsoVol, Surface, Length, RoughSph - SUMA/PROM)  - Matrices de correlaciÃ³n

**Error: Module not found**

```bash  - Pairplots para variables clave

pip install -r requirements.txt

```## ğŸ”¬ K-Fold Cross-Validation- Pruebas estadÃ­sticas (t-test, ANOVA) para diferencias entre grupos



**CUDA out of memory**

```python

# En train_classifier.py, reducir batch_size### Â¿Por quÃ© K-Fold para 20 participantes?**Herramientas**: Pandas, Seaborn, Plotly (para interactividad en Streamlit)

batch_size: 8  # o 4

```



**Model not converging****Problema con train/val split simple:**### Fase 2: PCA (ReducciÃ³n Dimensional)

- Aumentar learning_rate a 5e-3

- Reducir dropout a 0.2- Solo 16 participantes para entrenar (1 modelo)

- Aumentar max_epochs a 100-200

- Sensible al split aleatorio (puede ser "fÃ¡cil" o "difÃ­cil" por suerte)**Objetivo**: Identificar las componentes principales que explican la mayor varianza

**Puerto 8501 ocupado**

```bash- 1 mÃ©trica (ej: 75% accuracy) â†’ Â¿es representativa?

streamlit run app.py --server.port 8502

```**Proceso**:



**Error con scipy.stats.binom_test****SoluciÃ³n con K-Fold (K=5):**1. NormalizaciÃ³n de features (StandardScaler)

- Versiones nuevas de scipy usan `binomtest` en lugar de `binom_test`

- El cÃ³digo ya estÃ¡ actualizado para usar `binomtest`- Entrena 5 modelos independientes2. Aplicar PCA y visualizar varianza explicada (scree plot)



## ğŸ” Preguntas de InvestigaciÃ³n- Cada participante se valida exactamente 1 vez3. Proyectar datos en 2D/3D (PC1 vs PC2 vs PC3)



1. Â¿Existen diferencias morfolÃ³gicas significativas entre grupos CT y ELA?- MÃ©tricas robustas: **Mean Â± Std** (ej: 60% Â± 12%)4. Colorear por grupo, sexo y participante para identificar patrones

2. Â¿Las mÃ©tricas de superficie, volumen y longitud estÃ¡n correlacionadas?

3. Â¿El PCA revela separaciÃ³n natural entre grupos?- Refleja mejor la generalizaciÃ³n real

4. Â¿El LSTM captura patrones temporales en secuencias de mediciones?

5. Â¿Los resultados son estadÃ­sticamente significativos (p < 0.05)?**InterpretaciÃ³n**: 



## ğŸ“ PrÃ³ximos Pasos**Ejemplo con K=5:**- Â¿Se separan los grupos CT y ELA en el espacio PCA?



1. **Feature Engineering**: Explorar ratios, combinaciones no lineales```- Â¿QuÃ© mÃ©tricas contribuyen mÃ¡s a cada componente?

2. **Data Augmentation**: TÃ©cnicas para aumentar dataset pequeÃ±o

3. **Interpretabilidad**: SHAP values, attention weightsFold 1: Train [16 participants] â†’ Val [4 participants]

4. **MÃ¡s datos**: Si es posible, aumentar N participantes

5. **Ensemble**: Entrenar mÃºltiples modelos con diferentes seedsFold 2: Train [16 participants] â†’ Val [4 participants] (diferentes)### Fase 3: Variational Autoencoder (VAE) con PyTorch Lightning



---Fold 3: Train [16 participants] â†’ Val [4 participants] (diferentes)



**Ãšltima actualizaciÃ³n**: Noviembre 2025Fold 4: Train [16 participants] â†’ Val [4 participants] (diferentes)**Objetivo**: Aprender una representaciÃ³n probabilÃ­stica comprimida del espacio latente



## ğŸ‘¤ AutorFold 5: Train [16 participants] â†’ Val [4 participants] (diferentes)



Daniel Zangrando - AnÃ¡lisis de morfologÃ­a mitocondrial**Dos Arquitecturas Disponibles**:



---Resultado final: Val Accuracy = Mean(Fold1, ..., Fold5) Â± Std



**Nota**: Este proyecto prioriza **transparencia cientÃ­fica** con evaluaciÃ³n estadÃ­stica rigurosa (p-values), visualizaciones modernas e interactivas, y reproducibilidad completa mediante metadata de participantes train/val.```#### 1. VAE EstÃ¡ndar (Mean Pooling)


```

### CuÃ¡ndo usar cada modoInput (8 features agregadas) â†’ Encoder [64, 32] â†’ Latent 8D (Î¼, Ïƒ) â†’ Decoder [32, 64] â†’ Output (8 features)

                                                        â†“

| Modo | CuÃ¡ndo usar | Ventajas | Desventajas |                                                 Classifier [16] â†’ CT/ELA

|------|-------------|----------|-------------|```

| **Simple Split** | Testing rÃ¡pido, datasets grandes (N>100) | RÃ¡pido (1 modelo) | Menos robusto para N pequeÃ±o |- **Ventaja**: RÃ¡pido, simple, interpretable

| **K-Fold** | Datasets pequeÃ±os (N<100), reportes cientÃ­ficos | MÃ©tricas robustas, menos sesgo | MÃ¡s lento (K modelos) |- **Desventaja**: Pierde variabilidad intra-participante



## ğŸ“ Entrenamiento#### 2. LSTM-VAE (Sequences)

```

### OpciÃ³n 1: Desde Streamlit (Recomendado)Input (secuencias 4-36 mediciones Ã— 8 features) â†’ Bidirectional LSTM Encoder (2 capas, hidden=64)

                                                        â†“

1. Ejecutar `streamlit run app.py`                                                 Latent 16D (Î¼, Ïƒ)

2. Ir a pÃ¡gina **ğŸ“ Entrenar Modelo**                                                        â†“

3. Seleccionar modo:                                          Decoder LSTM (2 capas, hidden=64)

   - **Train/Val Split Simple** (rÃ¡pido)                                                        â†“

   - **K-Fold Cross-Validation** (robusto)                                          Output (secuencias reconstruidas)

4. Configurar hiperparÃ¡metros                                                        â†“

5. Click en **ğŸš€ Iniciar Entrenamiento**                                          Classifier [32, 16] â†’ CT/ELA

6. Ver resultados en pÃ¡gina **ğŸ¤– Clasificador**```

- **Ventaja**: Preserva variabilidad intra-participante, mayor capacidad

### OpciÃ³n 2: Desde terminal- **Desventaja**: MÃ¡s lento, mÃ¡s parÃ¡metros (~205k vs ~6k)



```bash**ConfiguraciÃ³n**:

# Entrenamiento con K-Fold (K=5)- **Framework**: PyTorch Lightning (simplifica entrenamiento, logging automÃ¡tico)

python scripts/train_classifier.py- **Loss**: ReconstrucciÃ³n + KL Divergence + ClasificaciÃ³n

- **Optimizer**: Adam con learning rate configurable

# Ver mÃ©tricas con TensorBoard- **Logging**: TensorBoard embebido en Streamlit (tiempo real)

tensorboard --logdir logs/lstm_classifier- **Callbacks**: Early Stopping, ModelCheckpoint, LearningRateMonitor

```

**Monitoreo en Tiempo Real**:

## ğŸ“ˆ InterpretaciÃ³n de Resultados- TensorBoard se muestra **dentro de Streamlit** durante el entrenamiento

- MÃ©tricas: loss, accuracy, KL divergence, reconstruction error

### MÃ©tricas K-Fold- Visualizaciones: curvas de aprendizaje, histogramas de pesos



**Ejemplo:** Val Accuracy: 60% Â± 12%**VisualizaciÃ³n**:

- ProyecciÃ³n del espacio latente en 2D/3D por grupo (CT/ELA)

- **Mean (60%)**: Accuracy promedio esperada en nuevos participantes- MÃ©tricas de clasificaciÃ³n (accuracy, confusion matrix)

- **Std (12%)**: Variabilidad entre folds- Comparar reconstrucciones vs datos originales

  - **Std < 10%**: Modelo estable âœ…- Identificar si la variabilidad intra-participante mejora la clasificaciÃ³n

  - **Std > 15%**: Alta variabilidad (normal con N=20) âš ï¸

### Fase 4: IntegraciÃ³n en Streamlit

### Accuracy Guidelines

**Arquitectura Multi-Page de Streamlit**:

| Accuracy | InterpretaciÃ³n |

|----------|----------------|La aplicaciÃ³n utiliza la estructura nativa de mÃºltiples pÃ¡ginas de Streamlit:

| **>70%** | âœ… Excelente - Hay seÃ±al morfomÃ©trica clara entre CT/ELA |

| **60-70%** | âš¡ Bueno - Hay separabilidad, puede mejorar con tuning |1. **Home (app.py)**: 

| **50-60%** | âš ï¸ Regular - Poco mejor que azar, revisar features |   - DescripciÃ³n del proyecto y dataset

| **<50%** | âŒ Malo - Modelo no estÃ¡ aprendiendo |   - MÃ©tricas generales

   - Vista previa de los datos

### Outputs guardados

2. **ğŸ“Š EDA (pages/1_ğŸ“Š_EDA.py)**:

**Simple Split:**   - SelecciÃ³n interactiva de mÃ©tricas y grupos

```   - GrÃ¡ficos de distribuciÃ³n (box, violin, histogram)

models/   - Matriz de correlaciÃ³n interactiva

â”œâ”€â”€ lstm_classifier-epoch=XX-val_acc=X.XXXX.ckpt   - Pruebas estadÃ­sticas automÃ¡ticas (t-test/ANOVA)

â””â”€â”€ ...   - Scatter plot matrix

   - AnÃ¡lisis por edad y participante

logs/lstm_classifier/

â””â”€â”€ version_0/3. **ï¿½ Entrenar Modelo (pages/2_ï¿½_Entrenar_Modelo.py)** â­ **NUEVO**:

    â””â”€â”€ events.out.tfevents...   - SelecciÃ³n de tipo de modelo (VAE estÃ¡ndar vs LSTM-VAE)

```   - ConfiguraciÃ³n interactiva de hiperparÃ¡metros:

     - Max epochs, learning rate, batch size, early stopping patience

**K-Fold:**   - **TensorBoard embebido en tiempo real** durante el entrenamiento

```   - VisualizaciÃ³n de mÃ©tricas: loss, accuracy, KL divergence

models/kfold_5/   - Ver entrenamientos anteriores y comparar runs

â”œâ”€â”€ fold1-epoch=XX-val_acc=X.XXXX.ckpt   - GuÃ­as contextuales sobre arquitecturas y hiperparÃ¡metros

â”œâ”€â”€ fold2-epoch=XX-val_acc=X.XXXX.ckpt   - Todo integrado - no necesitas abrir terminales adicionales

â”œâ”€â”€ ...

â””â”€â”€ summary.json  â† MÃ©tricas agregadas + hiperparÃ¡metros4. **ğŸ¤– Autoencoder (pages/3_ğŸ¤–_Autoencoder.py)**:

   - Carga de modelos entrenados (VAE o LSTM-VAE)

logs/lstm_classifier_kfold_5/   - DetecciÃ³n automÃ¡tica del tipo de modelo

â”œâ”€â”€ fold_1/   - VisualizaciÃ³n del espacio latente 2D/3D (Plotly interactivo)

â”œâ”€â”€ fold_2/   - MÃ©tricas de clasificaciÃ³n (accuracy, confusion matrix)

â””â”€â”€ ...   - AnÃ¡lisis de reconstrucciones

```   - ComparaciÃ³n conceptual con PCA

   - ExportaciÃ³n del espacio latente

## ğŸ› ï¸ Stack TecnolÃ³gico   - Ver logs histÃ³ricos de TensorBoard



| TecnologÃ­a | PropÃ³sito |**Ventajas de esta arquitectura**:

|-----------|-----------|- âœ… Todo nativo en Streamlit (sin necesidad de frameworks adicionales)

| **PyTorch** | Deep learning framework |- âœ… NavegaciÃ³n automÃ¡tica mediante sidebar

| **PyTorch Lightning** | Training loop, callbacks, logging |- âœ… Cache de datos para mejor rendimiento

| **Streamlit** | Web app interactiva |- âœ… Visualizaciones interactivas con Plotly

| **TensorBoard** | VisualizaciÃ³n de mÃ©tricas |- âœ… **TensorBoard embebido en tiempo real** - sin abrir ventanas adicionales

| **scikit-learn** | PCA, cross-validation, metrics |- âœ… Entrenamiento del modelo integrado en la UI

| **Plotly** | GrÃ¡ficos interactivos 3D |- âœ… ComparaciÃ³n fÃ¡cil entre VAE estÃ¡ndar y LSTM-VAE

| **Pandas/NumPy** | ManipulaciÃ³n de datos |- âœ… Logs nativos de PyTorch Lightning visibles en TensorBoard

- âœ… Workflow completo: configurar â†’ entrenar â†’ monitorear â†’ visualizar

## âš™ï¸ HiperparÃ¡metros Recomendados

## ğŸ†• CaracterÃ­sticas Destacadas

### Para empezar (baseline)

### TensorBoard en Tiempo Real

```yaml

hidden_dim: 64La nueva pÃ¡gina de entrenamiento incluye **TensorBoard embebido** que muestra mÃ©tricas en tiempo real:

num_layers: 2

dropout: 0.3- ğŸ“Š **Curvas de aprendizaje**: Loss y accuracy (train/validation)

learning_rate: 1e-3- ğŸ“ˆ **KL Divergence**: RegularizaciÃ³n del espacio latente

batch_size: 16- ğŸ” **Reconstruction Loss**: Calidad de reconstrucciÃ³n

max_epochs: 50-100- ğŸ¯ **Classification Metrics**: Accuracy de CT vs ELA

```- ğŸ“‰ **Learning Rate**: EvoluciÃ³n durante entrenamiento



### Si el modelo no converge**Sin necesidad de:**

- Abrir terminales adicionales

```yaml- Ejecutar comandos TensorBoard manualmente

learning_rate: 5e-3  # Aumentar- Cambiar entre ventanas

dropout: 0.2         # Reducir

hidden_dim: 128      # Aumentar capacidad**Todo en una sola interfaz web integrada.**

```

### Dos Modelos para Comparar

### Si hay overfitting (train_acc >> val_acc)

1. **VAE EstÃ¡ndar (Mean Pooling)**:

```yaml   - Agrega mÃºltiples mediciones por participante

dropout: 0.4-0.5     # Aumentar regularizaciÃ³n   - ~6,700 parÃ¡metros

hidden_dim: 32       # Reducir capacidad   - Entrenamiento rÃ¡pido (~2-5 min)

num_layers: 1        # Simplificar arquitectura   - Baseline sÃ³lido

val_split: 0.3       # MÃ¡s datos de validaciÃ³n

```2. **LSTM-VAE (Sequences)**:

   - Preserva variabilidad intra-participante

### Si hay underfitting (ambos accuracy bajos)   - ~205,850 parÃ¡metros

   - Entrenamiento mÃ¡s lento (~5-15 min)

```yaml   - Captura patrones temporales/secuenciales

hidden_dim: 128-256  # Aumentar capacidad

num_layers: 3        # MÃ¡s profundidad**Pregunta de InvestigaciÃ³n**: Â¿La variabilidad intra-participante mejora la clasificaciÃ³n CT vs ELA?

dropout: 0.2         # Menos regularizaciÃ³n

max_epochs: 100-200  # MÃ¡s tiempo de entrenamiento## ğŸ› ï¸ TecnologÃ­as Utilizadas

```

- **Python 3.8+**: Lenguaje base

## ğŸ› Troubleshooting- **Streamlit**: Framework para la aplicaciÃ³n web interactiva

- **PyTorch**: Framework de deep learning

**Error: Module not found**- **PyTorch Lightning**: Wrapper para simplificar entrenamiento y logging

```bash- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento (integrado con Lightning)

pip install -r requirements.txt- **Pandas & NumPy**: ManipulaciÃ³n de datos

```- **Scikit-learn**: PCA, normalizaciÃ³n, mÃ©tricas

- **Plotly & Seaborn**: Visualizaciones interactivas y estÃ¡ticas

**CUDA out of memory**- **Matplotlib**: GrÃ¡ficos complementarios

```python

# En train_classifier.py, reducir batch_size## ğŸ“Š Dataset

batch_size: 8  # o 4

```- **Formato**: CSV

- **Filas**: Observaciones de mitocondrias individuales

**Model not converging**- **Columnas**: 12 (mÃ©tricas morfolÃ³gicas + variables demogrÃ¡ficas)

- Aumentar learning_rate a 5e-3- **Grupos**: CT (Control) y ELA (Esclerosis Lateral AmiotrÃ³fica)

- Reducir dropout a 0.2

- Aumentar max_epochs a 100-200## ğŸ” Preguntas de InvestigaciÃ³n



**High variance across folds**1. Â¿Existen diferencias morfolÃ³gicas significativas entre grupos CT y ELA?

- Normal con N=202. Â¿Las mÃ©tricas de superficie, volumen y longitud estÃ¡n correlacionadas?

- Probar diferentes random_state3. Â¿El PCA revela separaciÃ³n natural entre grupos?

- Aumentar early_stopping_patience4. Â¿El autoencoder captura patrones no lineales que el PCA no detecta?

- Considerar feature engineering5. Â¿Hay clusterizaciÃ³n por participante o caracterÃ­sticas demogrÃ¡ficas?

6. **Â¿La variabilidad intra-participante (LSTM-VAE) mejora la clasificaciÃ³n vs mean pooling (VAE estÃ¡ndar)?** â­

**Puerto 8501 ocupado**

```bash## ğŸ“š DocumentaciÃ³n Adicional

streamlit run app.py --server.port 8502

```- **`LSTM_VAE_ARCHITECTURE.md`**: GuÃ­a tÃ©cnica detallada de la arquitectura LSTM-VAE

- **`docs/TRAINING_GUIDE.md`**: GuÃ­a completa de entrenamiento con TensorBoard

## ğŸ“ PrÃ³ximos Pasos- **`TENSORBOARD_INTEGRATION_SUMMARY.md`**: Resumen de integraciÃ³n y caracterÃ­sticas

- **`test_lstm_vae.py`**: Script de validaciÃ³n de la implementaciÃ³n LSTM-VAE

1. **Feature Engineering**: Explorar ratios, combinaciones no lineales- **`test_tensorboard_integration.py`**: Test de integraciÃ³n de TensorBoard

2. **Ensemble**: Promediar predicciones de los K modelos

3. **Interpretabilidad**: SHAP values, attention weights## ğŸ¤ Contribuciones

4. **MÃ¡s datos**: Si es posible, aumentar N participantes

5. **Transfer learning**: Pre-entrenar en datasets similaresEste es un proyecto de investigaciÃ³n. Las sugerencias y mejoras son bienvenidas.



---## ğŸ“ Licencia



**Ãšltima actualizaciÃ³n**: Noviembre 2025[Especificar licencia si aplica]


## ğŸ‘¤ Autor

Daniel - AnÃ¡lisis de morfologÃ­a mitocondrial

---

**Nota**: Este proyecto utiliza PyTorch Lightning para el entrenamiento del autoencoder, con **TensorBoard embebido en Streamlit** para monitorear mÃ©tricas en tiempo real. La integraciÃ³n completa permite entrenar, monitorear y visualizar modelos sin salir del navegador.

## ğŸ¯ Inicio RÃ¡pido

```bash
# 1. Clonar repositorio
git clone https://github.com/DanZangrando/mitochondrial-morphology.git
cd mitochondrial-morphology

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Ejecutar aplicaciÃ³n
streamlit run app.py

# 4. Entrenar modelo
# Ir a pÃ¡gina "ğŸ“ Entrenar Modelo" en el navegador
# Seleccionar tipo de modelo y configurar hiperparÃ¡metros
# Click en "ğŸš€ Iniciar Entrenamiento"
# TensorBoard se abre automÃ¡ticamente mostrando mÃ©tricas en tiempo real

# 5. Visualizar resultados
# Ir a pÃ¡gina "ğŸ¤– Autoencoder"
# Cargar modelo entrenado
# Explorar espacio latente y mÃ©tricas
```
