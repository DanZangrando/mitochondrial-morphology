# AnÃ¡lisis de MorfologÃ­a Mitocondrial

## ğŸ“Š DescripciÃ³n del Proyecto

Este proyecto analiza mÃ©tricas morfolÃ³gicas de mitocondrias para identificar patrones y diferencias entre grupos de estudio (Control vs ELA). Utilizamos tÃ©cnicas de anÃ¡lisis exploratorio, reducciÃ³n dimensional (PCA) y deep learning (Autoencoder) para visualizar el espacio latente y detectar posibles clusterizaciones.

### MÃ©tricas Analizadas

Los datos contienen las siguientes mÃ©tricas por mitocondria:

- **N mitocondrias**: NÃºmero de mitocondrias analizadas
- **IsoVol (SUMA/PROM)**: Volumen isomÃ©trico total y promedio
- **Surface (SUMA/PROM)**: Superficie total y promedio
- **Length (SUMA/PROM)**: Longitud total y promedio
- **RoughSph (SUMA/PROM)**: Ãndice de rugosidad/esfericidad total y promedio
- **Variables demogrÃ¡ficas**: Age, Sex, Group (CT/ELA), Participant

## ğŸ¯ Objetivos

1. **AnÃ¡lisis Exploratorio**: Examinar distribuciones y diferencias entre grupos (CT vs ELA), sexos y participantes
2. **PCA (AnÃ¡lisis de Componentes Principales)**: Reducir dimensionalidad y visualizar la varianza explicada
3. **Autoencoder**: Entrenar una red neuronal para comprimir la informaciÃ³n y explorar el espacio latente
4. **VisualizaciÃ³n**: Identificar si existe clusterizaciÃ³n natural de los datos segÃºn caracterÃ­sticas morfolÃ³gicas

## ğŸ—ï¸ Estructura del Proyecto

```
mitochondrial-morphology/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data.csv                    # Dataset original
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py              # Carga y preprocesamiento de datos
â”‚   â”œâ”€â”€ pca_analysis.py             # ImplementaciÃ³n del PCA
â”‚   â”œâ”€â”€ autoencoder.py              # Arquitectura del Autoencoder (PyTorch Lightning)
â”‚   â””â”€â”€ utils.py                    # Funciones auxiliares y visualizaciÃ³n
â”‚
â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ 1_ğŸ“Š_EDA.py                 # PÃ¡gina de AnÃ¡lisis Exploratorio
â”‚   â”œâ”€â”€ 2_ï¿½_Entrenar_Modelo.py     # PÃ¡gina de Entrenamiento con TensorBoard
â”‚   â””â”€â”€ 3_ğŸ¤–_Autoencoder.py         # PÃ¡gina de VisualizaciÃ³n de Modelos
â”‚
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ train_autoencoder.py        # Script para entrenar el autoencoder
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ .gitkeep                    # Modelos entrenados guardados aquÃ­
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ .gitkeep                    # Logs de TensorBoard (Lightning)
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                 # ConfiguraciÃ³n del proyecto
â”‚
â”œâ”€â”€ app.py                          # AplicaciÃ³n Streamlit principal (home)
â”œâ”€â”€ requirements.txt                # Dependencias del proyecto
â”œâ”€â”€ .gitignore                      # Archivos a ignorar en Git
â””â”€â”€ README.md                       # Este archivo
```

### JustificaciÃ³n de la Estructura

- **`src/`**: MÃ³dulos reutilizables para anÃ¡lisis y modelado (backend lÃ³gico)
- **`pages/`**: PÃ¡ginas de Streamlit - arquitectura multi-page nativa de Streamlit
- **`scripts/`**: Scripts Python ejecutables (ej: entrenamiento del autoencoder)
- **`models/`**: Checkpoints del autoencoder entrenado (generados por PyTorch Lightning)
- **`logs/`**: Logs de TensorBoard generados automÃ¡ticamente por PyTorch Lightning
- **`config/`**: Archivo YAML centralizado con todos los parÃ¡metros del proyecto
- **`app.py`**: PÃ¡gina principal de Streamlit (home), punto de entrada de la aplicaciÃ³n

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos

- Python 3.8+
- pip o conda

### 1. Clonar el Repositorio

```bash
git clone <URL_DEL_REPOSITORIO>
cd mitochondrial-morphology
```

### 2. Crear Entorno Virtual (Recomendado)

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Ejecutar la AplicaciÃ³n Streamlit

```bash
streamlit run app.py
```

La aplicaciÃ³n se abrirÃ¡ en tu navegador (por defecto: `http://localhost:8501`)

**NavegaciÃ³n**: La aplicaciÃ³n usa la arquitectura multi-page de Streamlit:
- **Home (app.py)**: PÃ¡gina principal con descripciÃ³n del proyecto
- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo
- **ï¿½ Entrenar Modelo**: Entrenar VAE/LSTM-VAE con TensorBoard en tiempo real
- **ğŸ¤– Autoencoder**: VisualizaciÃ³n del espacio latente y mÃ©tricas

### 5. Entrenar el Autoencoder

Puedes entrenar el autoencoder de dos formas:

**OpciÃ³n A - Desde la interfaz web (Recomendado)**:
1. Ejecuta la app: `streamlit run app.py`
2. Ve a la pÃ¡gina "ğŸ“ Entrenar Modelo"
3. Selecciona el tipo de modelo:
   - **VAE EstÃ¡ndar**: Agrega mediciones por participante (mean pooling)
   - **LSTM-VAE**: Preserva variabilidad intra-participante (secuencias completas)
4. Configura hiperparÃ¡metros (epochs, learning rate, batch size, patience)
5. Haz clic en "ğŸš€ Iniciar Entrenamiento"
6. **TensorBoard se abre automÃ¡ticamente en la misma pÃ¡gina** mostrando mÃ©tricas en tiempo real

**OpciÃ³n B - Desde la terminal**:
```bash
# VAE estÃ¡ndar
python scripts/train_autoencoder.py

# LSTM-VAE (preserva variabilidad intra-participante)
python scripts/train_autoencoder.py --lstm
```

### 6. Ver Logs de TensorBoard

**Durante el entrenamiento desde Streamlit**: TensorBoard se muestra automÃ¡ticamente en un iframe embebido.

**Manualmente** (opcional):
```bash
tensorboard --logdir=logs/
```

Abre tu navegador en `http://localhost:6006` para ver mÃ©tricas de entrenamiento, grÃ¡ficos de pÃ©rdida, y mÃ¡s.

## ğŸ“ˆ Estrategia de AnÃ¡lisis

### Fase 1: AnÃ¡lisis Exploratorio de Datos (EDA)

**Objetivo**: Comprender la distribuciÃ³n y relaciones de las mÃ©tricas

**TÃ©cnicas**:
- EstadÃ­sticas descriptivas por grupo (CT vs ELA)
- Visualizaciones:
  - Distribuciones (histogramas, boxplots) por grupo y sexo
  - Matrices de correlaciÃ³n
  - Pairplots para variables clave
- Pruebas estadÃ­sticas (t-test, ANOVA) para diferencias entre grupos

**Herramientas**: Pandas, Seaborn, Plotly (para interactividad en Streamlit)

### Fase 2: PCA (ReducciÃ³n Dimensional)

**Objetivo**: Identificar las componentes principales que explican la mayor varianza

**Proceso**:
1. NormalizaciÃ³n de features (StandardScaler)
2. Aplicar PCA y visualizar varianza explicada (scree plot)
3. Proyectar datos en 2D/3D (PC1 vs PC2 vs PC3)
4. Colorear por grupo, sexo y participante para identificar patrones

**InterpretaciÃ³n**: 
- Â¿Se separan los grupos CT y ELA en el espacio PCA?
- Â¿QuÃ© mÃ©tricas contribuyen mÃ¡s a cada componente?

### Fase 3: Variational Autoencoder (VAE) con PyTorch Lightning

**Objetivo**: Aprender una representaciÃ³n probabilÃ­stica comprimida del espacio latente

**Dos Arquitecturas Disponibles**:

#### 1. VAE EstÃ¡ndar (Mean Pooling)
```
Input (8 features agregadas) â†’ Encoder [64, 32] â†’ Latent 8D (Î¼, Ïƒ) â†’ Decoder [32, 64] â†’ Output (8 features)
                                                        â†“
                                                 Classifier [16] â†’ CT/ELA
```
- **Ventaja**: RÃ¡pido, simple, interpretable
- **Desventaja**: Pierde variabilidad intra-participante

#### 2. LSTM-VAE (Sequences)
```
Input (secuencias 4-36 mediciones Ã— 8 features) â†’ Bidirectional LSTM Encoder (2 capas, hidden=64)
                                                        â†“
                                                 Latent 16D (Î¼, Ïƒ)
                                                        â†“
                                          Decoder LSTM (2 capas, hidden=64)
                                                        â†“
                                          Output (secuencias reconstruidas)
                                                        â†“
                                          Classifier [32, 16] â†’ CT/ELA
```
- **Ventaja**: Preserva variabilidad intra-participante, mayor capacidad
- **Desventaja**: MÃ¡s lento, mÃ¡s parÃ¡metros (~205k vs ~6k)

**ConfiguraciÃ³n**:
- **Framework**: PyTorch Lightning (simplifica entrenamiento, logging automÃ¡tico)
- **Loss**: ReconstrucciÃ³n + KL Divergence + ClasificaciÃ³n
- **Optimizer**: Adam con learning rate configurable
- **Logging**: TensorBoard embebido en Streamlit (tiempo real)
- **Callbacks**: Early Stopping, ModelCheckpoint, LearningRateMonitor

**Monitoreo en Tiempo Real**:
- TensorBoard se muestra **dentro de Streamlit** durante el entrenamiento
- MÃ©tricas: loss, accuracy, KL divergence, reconstruction error
- Visualizaciones: curvas de aprendizaje, histogramas de pesos

**VisualizaciÃ³n**:
- ProyecciÃ³n del espacio latente en 2D/3D por grupo (CT/ELA)
- MÃ©tricas de clasificaciÃ³n (accuracy, confusion matrix)
- Comparar reconstrucciones vs datos originales
- Identificar si la variabilidad intra-participante mejora la clasificaciÃ³n

### Fase 4: IntegraciÃ³n en Streamlit

**Arquitectura Multi-Page de Streamlit**:

La aplicaciÃ³n utiliza la estructura nativa de mÃºltiples pÃ¡ginas de Streamlit:

1. **Home (app.py)**: 
   - DescripciÃ³n del proyecto y dataset
   - MÃ©tricas generales
   - Vista previa de los datos

2. **ğŸ“Š EDA (pages/1_ğŸ“Š_EDA.py)**:
   - SelecciÃ³n interactiva de mÃ©tricas y grupos
   - GrÃ¡ficos de distribuciÃ³n (box, violin, histogram)
   - Matriz de correlaciÃ³n interactiva
   - Pruebas estadÃ­sticas automÃ¡ticas (t-test/ANOVA)
   - Scatter plot matrix
   - AnÃ¡lisis por edad y participante

3. **ï¿½ Entrenar Modelo (pages/2_ï¿½_Entrenar_Modelo.py)** â­ **NUEVO**:
   - SelecciÃ³n de tipo de modelo (VAE estÃ¡ndar vs LSTM-VAE)
   - ConfiguraciÃ³n interactiva de hiperparÃ¡metros:
     - Max epochs, learning rate, batch size, early stopping patience
   - **TensorBoard embebido en tiempo real** durante el entrenamiento
   - VisualizaciÃ³n de mÃ©tricas: loss, accuracy, KL divergence
   - Ver entrenamientos anteriores y comparar runs
   - GuÃ­as contextuales sobre arquitecturas y hiperparÃ¡metros
   - Todo integrado - no necesitas abrir terminales adicionales

4. **ğŸ¤– Autoencoder (pages/3_ğŸ¤–_Autoencoder.py)**:
   - Carga de modelos entrenados (VAE o LSTM-VAE)
   - DetecciÃ³n automÃ¡tica del tipo de modelo
   - VisualizaciÃ³n del espacio latente 2D/3D (Plotly interactivo)
   - MÃ©tricas de clasificaciÃ³n (accuracy, confusion matrix)
   - AnÃ¡lisis de reconstrucciones
   - ComparaciÃ³n conceptual con PCA
   - ExportaciÃ³n del espacio latente
   - Ver logs histÃ³ricos de TensorBoard

**Ventajas de esta arquitectura**:
- âœ… Todo nativo en Streamlit (sin necesidad de frameworks adicionales)
- âœ… NavegaciÃ³n automÃ¡tica mediante sidebar
- âœ… Cache de datos para mejor rendimiento
- âœ… Visualizaciones interactivas con Plotly
- âœ… **TensorBoard embebido en tiempo real** - sin abrir ventanas adicionales
- âœ… Entrenamiento del modelo integrado en la UI
- âœ… ComparaciÃ³n fÃ¡cil entre VAE estÃ¡ndar y LSTM-VAE
- âœ… Logs nativos de PyTorch Lightning visibles en TensorBoard
- âœ… Workflow completo: configurar â†’ entrenar â†’ monitorear â†’ visualizar

## ğŸ†• CaracterÃ­sticas Destacadas

### TensorBoard en Tiempo Real

La nueva pÃ¡gina de entrenamiento incluye **TensorBoard embebido** que muestra mÃ©tricas en tiempo real:

- ğŸ“Š **Curvas de aprendizaje**: Loss y accuracy (train/validation)
- ğŸ“ˆ **KL Divergence**: RegularizaciÃ³n del espacio latente
- ğŸ” **Reconstruction Loss**: Calidad de reconstrucciÃ³n
- ğŸ¯ **Classification Metrics**: Accuracy de CT vs ELA
- ğŸ“‰ **Learning Rate**: EvoluciÃ³n durante entrenamiento

**Sin necesidad de:**
- Abrir terminales adicionales
- Ejecutar comandos TensorBoard manualmente
- Cambiar entre ventanas

**Todo en una sola interfaz web integrada.**

### Dos Modelos para Comparar

1. **VAE EstÃ¡ndar (Mean Pooling)**:
   - Agrega mÃºltiples mediciones por participante
   - ~6,700 parÃ¡metros
   - Entrenamiento rÃ¡pido (~2-5 min)
   - Baseline sÃ³lido

2. **LSTM-VAE (Sequences)**:
   - Preserva variabilidad intra-participante
   - ~205,850 parÃ¡metros
   - Entrenamiento mÃ¡s lento (~5-15 min)
   - Captura patrones temporales/secuenciales

**Pregunta de InvestigaciÃ³n**: Â¿La variabilidad intra-participante mejora la clasificaciÃ³n CT vs ELA?

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.8+**: Lenguaje base
- **Streamlit**: Framework para la aplicaciÃ³n web interactiva
- **PyTorch**: Framework de deep learning
- **PyTorch Lightning**: Wrapper para simplificar entrenamiento y logging
- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento (integrado con Lightning)
- **Pandas & NumPy**: ManipulaciÃ³n de datos
- **Scikit-learn**: PCA, normalizaciÃ³n, mÃ©tricas
- **Plotly & Seaborn**: Visualizaciones interactivas y estÃ¡ticas
- **Matplotlib**: GrÃ¡ficos complementarios

## ğŸ“Š Dataset

- **Formato**: CSV
- **Filas**: Observaciones de mitocondrias individuales
- **Columnas**: 12 (mÃ©tricas morfolÃ³gicas + variables demogrÃ¡ficas)
- **Grupos**: CT (Control) y ELA (Esclerosis Lateral AmiotrÃ³fica)

## ğŸ” Preguntas de InvestigaciÃ³n

1. Â¿Existen diferencias morfolÃ³gicas significativas entre grupos CT y ELA?
2. Â¿Las mÃ©tricas de superficie, volumen y longitud estÃ¡n correlacionadas?
3. Â¿El PCA revela separaciÃ³n natural entre grupos?
4. Â¿El autoencoder captura patrones no lineales que el PCA no detecta?
5. Â¿Hay clusterizaciÃ³n por participante o caracterÃ­sticas demogrÃ¡ficas?
6. **Â¿La variabilidad intra-participante (LSTM-VAE) mejora la clasificaciÃ³n vs mean pooling (VAE estÃ¡ndar)?** â­

## ğŸ“š DocumentaciÃ³n Adicional

- **`LSTM_VAE_ARCHITECTURE.md`**: GuÃ­a tÃ©cnica detallada de la arquitectura LSTM-VAE
- **`docs/TRAINING_GUIDE.md`**: GuÃ­a completa de entrenamiento con TensorBoard
- **`TENSORBOARD_INTEGRATION_SUMMARY.md`**: Resumen de integraciÃ³n y caracterÃ­sticas
- **`test_lstm_vae.py`**: Script de validaciÃ³n de la implementaciÃ³n LSTM-VAE
- **`test_tensorboard_integration.py`**: Test de integraciÃ³n de TensorBoard

## ğŸ¤ Contribuciones

Este es un proyecto de investigaciÃ³n. Las sugerencias y mejoras son bienvenidas.

## ğŸ“ Licencia

[Especificar licencia si aplica]

## ğŸ‘¤ Autor

Daniel - AnÃ¡lisis de morfologÃ­a mitocondrial

---

**Nota**: Este proyecto utiliza PyTorch Lightning para el entrenamiento del autoencoder, con **TensorBoard embebido en Streamlit** para monitorear mÃ©tricas en tiempo real. La integraciÃ³n completa permite entrenar, monitorear y visualizar modelos sin salir del navegador.

## ğŸ¯ Inicio RÃ¡pido

```bash
# 1. Clonar repositorio
git clone https://github.com/DanZangrando/mitochondrial-morphology.git
cd mitochondrial-morphology

# 2. Instalar dependencias
pip install -r requirements.txt

# 3. Ejecutar aplicaciÃ³n
streamlit run app.py

# 4. Entrenar modelo
# Ir a pÃ¡gina "ğŸ“ Entrenar Modelo" en el navegador
# Seleccionar tipo de modelo y configurar hiperparÃ¡metros
# Click en "ğŸš€ Iniciar Entrenamiento"
# TensorBoard se abre automÃ¡ticamente mostrando mÃ©tricas en tiempo real

# 5. Visualizar resultados
# Ir a pÃ¡gina "ğŸ¤– Autoencoder"
# Cargar modelo entrenado
# Explorar espacio latente y mÃ©tricas
```
