# AnÃ¡lisis de MorfologÃ­a Mitocondrial

## ğŸ“Š DescripciÃ³n del Proyecto

Este proyecto analiza mÃ©tricas morfolÃ³gicas de mitocondrias para identificar patrones y diferencias entre grupos de estudio (Control vs ELA). Utilizamos tÃ©cnicas de anÃ¡lisis exploratorio, reducciÃ³n dimensional (PCA) y deep learning (Autoencoder) para visualizar el espacio latente y detectar posibles clusterizaciones.

### MÃ©tricas Analizadas

Los datos contienen las siguientes mÃ©tricas por mitocondria:

- **N mitocondrias**: NÃºmero de mitocondrias analizadas
- **IsoVol (SUMA/PROM)**: Volumen isomÃ©trico total y promedio
- **Surface (SUMA/PROM)**: Superficie total y promedio
- **Length (SUMA/PROM)**: Longitud total y promedio
- **RoughSph (SUMA/PROM)**: Ãndice de rugosidad/esfericidad total y promedio
- **Variables demogrÃ¡ficas**: Age, Sex, Group (CT/ELA), Participant

## ğŸ¯ Objetivos

1. **AnÃ¡lisis Exploratorio**: Examinar distribuciones y diferencias entre grupos (CT vs ELA), sexos y participantes
2. **PCA (AnÃ¡lisis de Componentes Principales)**: Reducir dimensionalidad y visualizar la varianza explicada
3. **Autoencoder**: Entrenar una red neuronal para comprimir la informaciÃ³n y explorar el espacio latente
4. **VisualizaciÃ³n**: Identificar si existe clusterizaciÃ³n natural de los datos segÃºn caracterÃ­sticas morfolÃ³gicas

## ğŸ—ï¸ Estructura del Proyecto

```
mitochondrial-morphology/
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ data.csv                    # Dataset original
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data_loader.py              # Carga y preprocesamiento de datos
â”‚   â”œâ”€â”€ exploratory_analysis.py     # AnÃ¡lisis exploratorio (EDA)
â”‚   â”œâ”€â”€ pca_analysis.py             # ImplementaciÃ³n del PCA
â”‚   â”œâ”€â”€ autoencoder.py              # Arquitectura del Autoencoder (PyTorch)
â”‚   â””â”€â”€ utils.py                    # Funciones auxiliares
â”‚
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_exploratory_analysis.ipynb   # EDA detallado
â”‚   â”œâ”€â”€ 02_pca_analysis.ipynb           # AnÃ¡lisis PCA
â”‚   â””â”€â”€ 03_autoencoder_training.ipynb   # Entrenamiento del autoencoder
â”‚
â”œâ”€â”€ models/
â”‚   â””â”€â”€ .gitkeep                    # Modelos entrenados guardados aquÃ­
â”‚
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ .gitkeep                    # Logs de TensorBoard (Lightning)
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                 # ConfiguraciÃ³n del proyecto
â”‚
â”œâ”€â”€ app.py                          # AplicaciÃ³n Streamlit principal
â”œâ”€â”€ requirements.txt                # Dependencias del proyecto
â”œâ”€â”€ .gitignore                      # Archivos a ignorar en Git
â””â”€â”€ README.md                       # Este archivo
```

### JustificaciÃ³n de la Estructura

- **`src/`**: Contiene mÃ³dulos reutilizables para anÃ¡lisis y modelado, facilitando la separaciÃ³n de lÃ³gica
- **`notebooks/`**: AnÃ¡lisis exploratorios paso a paso, Ãºtiles para documentaciÃ³n y experimentaciÃ³n
- **`models/`**: Almacena checkpoints del autoencoder entrenado
- **`logs/`**: PyTorch Lightning genera logs automÃ¡ticamente para TensorBoard
- **`config/`**: Centraliza parÃ¡metros (rutas, hiperparÃ¡metros) en un solo archivo
- **`app.py`**: Interfaz interactiva Streamlit que integra todos los anÃ¡lisis

## ğŸš€ InstalaciÃ³n y Uso

### Prerrequisitos

- Python 3.8+
- pip o conda

### 1. Clonar el Repositorio

```bash
git clone <URL_DEL_REPOSITORIO>
cd mitochondrial-morphology
```

### 2. Crear Entorno Virtual (Recomendado)

```bash
python -m venv venv
source venv/bin/activate  # En Windows: venv\Scripts\activate
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

### 4. Ejecutar la AplicaciÃ³n Streamlit

```bash
streamlit run app.py
```

La aplicaciÃ³n se abrirÃ¡ en tu navegador (por defecto: `http://localhost:8501`)

### 5. Ver Logs de TensorBoard (Opcional)

Durante el entrenamiento del autoencoder, puedes monitorear el progreso en tiempo real:

```bash
tensorboard --logdir=logs/
```

## ğŸ“ˆ Estrategia de AnÃ¡lisis

### Fase 1: AnÃ¡lisis Exploratorio de Datos (EDA)

**Objetivo**: Comprender la distribuciÃ³n y relaciones de las mÃ©tricas

**TÃ©cnicas**:
- EstadÃ­sticas descriptivas por grupo (CT vs ELA)
- Visualizaciones:
  - Distribuciones (histogramas, boxplots) por grupo y sexo
  - Matrices de correlaciÃ³n
  - Pairplots para variables clave
- Pruebas estadÃ­sticas (t-test, ANOVA) para diferencias entre grupos

**Herramientas**: Pandas, Seaborn, Plotly (para interactividad en Streamlit)

### Fase 2: PCA (ReducciÃ³n Dimensional)

**Objetivo**: Identificar las componentes principales que explican la mayor varianza

**Proceso**:
1. NormalizaciÃ³n de features (StandardScaler)
2. Aplicar PCA y visualizar varianza explicada (scree plot)
3. Proyectar datos en 2D/3D (PC1 vs PC2 vs PC3)
4. Colorear por grupo, sexo y participante para identificar patrones

**InterpretaciÃ³n**: 
- Â¿Se separan los grupos CT y ELA en el espacio PCA?
- Â¿QuÃ© mÃ©tricas contribuyen mÃ¡s a cada componente?

### Fase 3: Autoencoder con PyTorch Lightning

**Objetivo**: Aprender una representaciÃ³n comprimida del espacio latente

**Arquitectura Propuesta**:
```
Input (8 features) â†’ Encoder (Dense layers) â†’ Latent Space (2-3D) â†’ Decoder â†’ Output (8 features)
```

**ConfiguraciÃ³n**:
- **Framework**: PyTorch Lightning (simplifica entrenamiento, logging automÃ¡tico)
- **Loss**: MSE (Mean Squared Error) para reconstrucciÃ³n
- **Optimizer**: Adam
- **Logging**: TensorBoard nativo de Lightning (`TensorBoardLogger`)
- **Callbacks**: Early Stopping, ModelCheckpoint

**VisualizaciÃ³n**:
- ProyecciÃ³n del espacio latente en 2D/3D
- Comparar con PCA: Â¿El autoencoder captura estructura no lineal?
- Visualizar reconstrucciones vs datos originales

### Fase 4: IntegraciÃ³n en Streamlit

**Componentes de la App**:

1. **PÃ¡gina de inicio**: DescripciÃ³n del proyecto y dataset
2. **EDA Interactivo**:
   - Selector de mÃ©tricas y grupos
   - GrÃ¡ficos interactivos (Plotly)
3. **PCA Visualization**:
   - Sliders para seleccionar componentes
   - Scatter plots coloreados por grupo/sexo
4. **Autoencoder Dashboard**:
   - VisualizaciÃ³n del espacio latente
   - MÃ©tricas de entrenamiento (integradas desde TensorBoard)
   - ComparaciÃ³n de reconstrucciones
5. **Insights y Conclusiones**:
   - Resumen de hallazgos
   - Recomendaciones

**Ventaja**: Todo nativo en Streamlit, sin necesidad de exportar imÃ¡genes estÃ¡ticas

## ğŸ› ï¸ TecnologÃ­as Utilizadas

- **Python 3.8+**: Lenguaje base
- **Streamlit**: Framework para la aplicaciÃ³n web interactiva
- **PyTorch**: Framework de deep learning
- **PyTorch Lightning**: Wrapper para simplificar entrenamiento y logging
- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento (integrado con Lightning)
- **Pandas & NumPy**: ManipulaciÃ³n de datos
- **Scikit-learn**: PCA, normalizaciÃ³n, mÃ©tricas
- **Plotly & Seaborn**: Visualizaciones interactivas y estÃ¡ticas
- **Matplotlib**: GrÃ¡ficos complementarios

## ğŸ“Š Dataset

- **Formato**: CSV
- **Filas**: Observaciones de mitocondrias individuales
- **Columnas**: 12 (mÃ©tricas morfolÃ³gicas + variables demogrÃ¡ficas)
- **Grupos**: CT (Control) y ELA (Esclerosis Lateral AmiotrÃ³fica)

## ğŸ” Preguntas de InvestigaciÃ³n

1. Â¿Existen diferencias morfolÃ³gicas significativas entre grupos CT y ELA?
2. Â¿Las mÃ©tricas de superficie, volumen y longitud estÃ¡n correlacionadas?
3. Â¿El PCA revela separaciÃ³n natural entre grupos?
4. Â¿El autoencoder captura patrones no lineales que el PCA no detecta?
5. Â¿Hay clusterizaciÃ³n por participante o caracterÃ­sticas demogrÃ¡ficas?

## ğŸ¤ Contribuciones

Este es un proyecto de investigaciÃ³n. Las sugerencias y mejoras son bienvenidas.

## ğŸ“ Licencia

[Especificar licencia si aplica]

## ğŸ‘¤ Autor

Daniel - AnÃ¡lisis de morfologÃ­a mitocondrial

---

**Nota**: Este proyecto utiliza PyTorch Lightning para el entrenamiento del autoencoder, lo que permite una integraciÃ³n nativa con TensorBoard para monitorear mÃ©tricas en tiempo real, que luego se visualizan directamente en la aplicaciÃ³n Streamlit.
