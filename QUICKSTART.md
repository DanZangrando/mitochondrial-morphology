# Quick Start Guide - Mitochondrial Morphology Analysis# Quick Start Guide - Mitochondrial Morphology Analysis# Quick Start Guide - Mitochondrial Morphology Analysis



## ğŸš€ Inicio RÃ¡pido



### 1. Instalar dependencias## ğŸš€ Inicio RÃ¡pido## ğŸš€ Inicio RÃ¡pido



```bash

pip install -r requirements.txt

```### 1. Instalar dependencias### 1. Instalar dependencias



### 2. Ejecutar la aplicaciÃ³n```bash```bash



```bash# Crear entorno virtual (recomendado)pip install -r requirements.txt

streamlit run app.py

```python -m venv venv```



### 3. NavegaciÃ³nsource venv/bin/activate  # Linux/Mac



La aplicaciÃ³n se abrirÃ¡ en `http://localhost:8501` con 3 pÃ¡ginas:# venv\Scripts\activate  # Windows### 2. Ejecutar la aplicaciÃ³n



- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo```bash

- **ğŸ¯ PCA**: ReducciÃ³n dimensional con PCA

- **ğŸ¯ Entrenar Clasificador**: Entrenamiento + EvaluaciÃ³n integrada# Instalar dependenciasstreamlit run app.py



### 4. Entrenar el Clasificadorpip install -r requirements.txt```



**OpciÃ³n A - Desde la interfaz web (Recomendado)**:```



1. Ve a la pÃ¡gina "ğŸ¯ Entrenar Clasificador"### 3. NavegaciÃ³n

2. Configura hiperparÃ¡metros en el sidebar:

   - Hidden Dim (64 por defecto)### 2. Ejecutar la aplicaciÃ³n- **Home**: Vista general del proyecto y dataset

   - Learning Rate (1e-3)

   - Dropout (0.3)```bash- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo

   - Epochs (50)

   - Batch Size (16)streamlit run app.py- **ğŸ¯ PCA**: ReducciÃ³n dimensional con PCA

3. Click en "ğŸš€ Iniciar Entrenamiento"

4. Ve el progreso en tiempo real```- **ğŸ¤– Autoencoder**: Entrenamiento y visualizaciÃ³n del espacio latente

5. **Resultados se muestran automÃ¡ticamente** al terminar



**OpciÃ³n B - Desde terminal**:

La aplicaciÃ³n se abrirÃ¡ en `http://localhost:8501`### 4. Entrenar el Autoencoder

```bash

python scripts/train_classifier.py

```

### 3. NavegaciÃ³n**OpciÃ³n A**: Desde la interfaz web (pÃ¡gina Autoencoder)

### 5. Ver logs de entrenamiento

- **Home**: Vista general del proyecto y dataset

```bash

tensorboard --logdir=logs/lstm_classifier- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo**OpciÃ³n B**: Desde terminal

```

- **ğŸ¯ PCA**: ReducciÃ³n dimensional con PCA```bash

Luego abre: http://localhost:6006

- **ğŸ“ Entrenar Modelo**: Entrenamiento de LSTM Classifier con K-Fold CVpython scripts/train_autoencoder.py

## ğŸ“Š Estructura del Dataset

- **ğŸ¤– Clasificador**: VisualizaciÃ³n de resultados```

- **Observaciones**: 306 mediciones de mitocondrias

- **Participantes**: 20 (10 CT, 10 ELA)

- **Grupos**: 

  - CT (Control): 167 observaciones### 4. Entrenar el Clasificador### 5. Ver logs de entrenamiento

  - ELA (Esclerosis Lateral AmiotrÃ³fica): 139 observaciones

- **MÃ©tricas**: 8 features morfolÃ³gicas (IsoVol, Surface, Length, RoughSph - SUMA/PROM)```bash

- **Variables demogrÃ¡ficas**: Age, Sex, Participant (no usadas en el modelo)

**OpciÃ³n A**: Desde la interfaz web (pÃ¡gina ğŸ“ Entrenar Modelo)tensorboard --logdir=logs/

## ğŸ¯ Objetivos

- Selecciona modo: Train/Val Split Simple o **K-Fold CV (recomendado)**```

1. **EDA**: Identificar diferencias estadÃ­sticas entre grupos CT y ELA

2. **PCA**: Visualizar estructura de datos en espacio reducido- Configura hiperparÃ¡metros (hidden_dim, learning_rate, dropout, etc.)Luego abre: http://localhost:6006

3. **LSTM Classifier**: Clasificar participantes CT vs ELA con significancia estadÃ­stica

- Click en "ğŸš€ Iniciar Entrenamiento"

## ğŸ“ˆ EvaluaciÃ³n con P-Value

- Ve mÃ©tricas en tiempo real con TensorBoard## ğŸ“Š Estructura del Dataset

### Doble EvaluaciÃ³n



Al entrenar, verÃ¡s **dos matrices de confusiÃ³n**:

**OpciÃ³n B**: Desde terminal- **Observaciones**: 385 mediciones de mitocondrias

1. **ValidaciÃ³n** (azul):

   - Solo participantes de validaciÃ³n```bash- **Participantes**: 20 (10 CT, 10 ELA)

   - MÃ©tricas reales de generalizaciÃ³n

   - **Incluye p-value del test binomial**# Entrenar con K-Fold Cross-Validation (K=5 por defecto)- **Grupos**: 



2. **Dataset Completo** (verde):python scripts/train_classifier.py  - CT (Control): 195 observaciones

   - Todos los participantes (train + val)

   - Solo para referencia```  - ELA (Esclerosis Lateral AmiotrÃ³fica): 190 observaciones



### InterpretaciÃ³n del P-Value- **MÃ©tricas**: 8 features morfolÃ³gicas (IsoVol, Surface, Length, RoughSph)



El test binomial evalÃºa: Â¿El modelo clasifica mejor que el azar (50%)?### 5. Ver logs de entrenamiento- **Variables demogrÃ¡ficas**: Age, Sex, Participant



- **p < 0.05**: âœ… Significativo - el modelo aprende```bash

- **p â‰¥ 0.05**: âš ï¸ No significativo - puede ser azar

tensorboard --logdir=logs/lstm_classifier## ğŸ¯ Objetivos

**SÃ­mbolos**:

- `***`: p < 0.001 (altamente significativo)```

- `**`: p < 0.01 (muy significativo)

- `*`: p < 0.05 (significativo)Luego abre: http://localhost:60061. **EDA**: Identificar diferencias estadÃ­sticas entre grupos CT y ELA

- `ns`: p â‰¥ 0.05 (no significativo)

2. **PCA**: Visualizar estructura de datos en espacio reducido

## ğŸ“ ConfiguraciÃ³n

## ğŸ“Š Estructura del Dataset3. **Autoencoder**: Capturar relaciones no lineales y explorar clusterizaciÃ³n

Edita `config/config.yaml` para modificar:



- Arquitectura del clasificador

- HiperparÃ¡metros de entrenamiento- **Observaciones**: 306 mediciones de mitocondrias## ğŸ“ ConfiguraciÃ³n

- Callbacks (early stopping, checkpointing)

- NÃºmero de componentes PCA- **Participantes**: 20 (10 CT, 10 ELA)

- Rutas de datos

- **Grupos**: Edita `config/config.yaml` para modificar:

## ğŸ› ï¸ Stack TecnolÃ³gico

  - CT (Control): 167 observaciones- Arquitectura del autoencoder

- **Streamlit**: Framework web interactivo

- **PyTorch + Lightning**: Deep learning con logging automÃ¡tico  - ELA (Esclerosis Lateral AmiotrÃ³fica): 139 observaciones- HiperparÃ¡metros de entrenamiento

- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento

- **Plotly**: GrÃ¡ficos interactivos modernos (confusion matrices)- **MÃ©tricas**: 8 features morfolÃ³gicas (IsoVol, Surface, Length, RoughSph - SUMA/PROM)- NÃºmero de componentes PCA

- **Scikit-learn**: NormalizaciÃ³n, stratification, mÃ©tricas

- **SciPy**: Test estadÃ­stico binomial- **Variables demogrÃ¡ficas**: Age, Sex, Participant (no usadas como input del modelo)- Rutas de datos

- **Pandas/NumPy**: ManipulaciÃ³n de datos



## âš¡ Tips

## ğŸ¯ Objetivos## ğŸ› ï¸ Stack TecnolÃ³gico

- Los datos se cachean automÃ¡ticamente en Streamlit (mejor rendimiento)

- Usa `Ctrl+C` en terminal para detener la app

- Los modelos entrenados se guardan en `models/`

- Cada modelo guarda metadata con participantes train/val en JSON1. **EDA**: Identificar diferencias estadÃ­sticas entre grupos CT y ELA- **Streamlit**: Framework web interactivo

- Los logs se generan automÃ¡ticamente en `logs/`

- Todos los grÃ¡ficos son interactivos (zoom, pan, hover)2. **PCA**: Visualizar estructura de datos en espacio reducido- **PyTorch + Lightning**: Deep learning con logging automÃ¡tico

- Las matrices de confusiÃ³n tienen gradientes de color modernos

3. **LSTM Classifier**: ClasificaciÃ³n supervisada CT vs ELA usando secuencias de longitud variable- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento

## ğŸ› Troubleshooting

4. **K-Fold CV**: Obtener mÃ©tricas robustas (mean Â± std) para dataset pequeÃ±o (N=20)- **Plotly**: GrÃ¡ficos interactivos 3D

**Error: Module not found**

```bash- **Scikit-learn**: PCA y preprocesamiento

pip install -r requirements.txt

```## ğŸ§  Modelo- **Pandas/NumPy**: ManipulaciÃ³n de datos



**No se encuentra el dataset**

- Verifica que `data/data.csv` existe

**LSTM Bidirectional Classifier**:## âš¡ Tips

**Error al entrenar**

- Verifica instalaciÃ³n de PyTorch: `pip install torch pytorch-lightning`- Input: (batch, seq_len, 8) - secuencias de longitud variable (4-36 mediciones/participante)

- Verifica scipy: `pip install scipy`

- 2 capas LSTM bidireccionales (hidden_dim=64)- Los datos se cachean automÃ¡ticamente en Streamlit (mejor rendimiento)

**Puerto 8501 ocupado**

```bash- Classifier head: FC 128â†’64â†’32â†’2 con Dropout- Usa `Ctrl+C` en terminal para detener la app

streamlit run app.py --server.port 8502

```- Loss: Cross Entropy- Los modelos entrenados se guardan en `models/`



**CUDA out of memory**- Optimizer: Adam + ReduceLROnPlateau- Los logs se generan automÃ¡ticamente en `logs/`

- Reduce batch_size (ej: 8 o 4)

- ~147K parÃ¡metros entrenables- Todos los grÃ¡ficos son interactivos (zoom, pan, hover)

**Modelo no converge**

- Aumenta learning_rate (5e-3)

- Reduce dropout (0.2)

- Aumenta max_epochs (100-200)## ğŸ“ ConfiguraciÃ³n## ğŸ› Troubleshooting



**Error con scipy.stats.binom_test**

- El cÃ³digo usa `binomtest` (versiÃ³n moderna)

- Si tienes scipy < 1.7, actualiza: `pip install --upgrade scipy`Edita `config/config.yaml` para modificar:**Error: Module not found**



## ğŸ¯ Flujo de Trabajo TÃ­pico- Arquitectura del clasificador```bash



1. **ExploraciÃ³n inicial**: PÃ¡gina EDA para entender distribuciones- HiperparÃ¡metros de entrenamientopip install -r requirements.txt

2. **AnÃ¡lisis PCA**: Ver si hay separaciÃ³n lineal CT vs ELA

3. **Entrenar modelo**: PÃ¡gina Entrenar Clasificador- Callbacks (early stopping, checkpointing)```

4. **Evaluar significancia**: Revisar p-value en matriz de validaciÃ³n

5. **Ajustar hiperparÃ¡metros** si es necesario- NÃºmero de componentes PCA

6. **Repetir con diferentes seeds** para robustez

- Rutas de datos**No se encuentra el dataset**

## ğŸ“Š MÃ©tricas Clave

- Verifica que `data/data.csv` existe

Al evaluar el modelo, observa:

## ğŸ”¬ K-Fold Cross-Validation

- **Accuracy de validaciÃ³n**: Â¿>70%? âœ… Excelente

- **P-value**: Â¿<0.05? âœ… Significativo estadÃ­sticamente**Error al entrenar**

- **Matriz de confusiÃ³n**: Â¿Balanceada entre CT/ELA?

- **Per-class accuracy**: Â¿Una clase mucho peor que otra?**Â¿Por quÃ© K-Fold para N=20?**- Verifica instalaciÃ³n de PyTorch: `pip install torch pytorch-lightning`



## ğŸ—‚ï¸ Archivos Generados



DespuÃ©s del entrenamiento:Con solo 20 participantes, un train/val split simple (16/4) es muy sensible al azar. K-Fold entrena K modelos independientes y reporta mÃ©tricas robustas:**Puerto 8501 ocupado**



``````bash

models/

â”œâ”€â”€ lstm_classifier-epoch=XX-val_acc=0.XXXX.ckpt        # Pesos del modelo**K=5 (recomendado)**:streamlit run app.py --server.port 8502

â””â”€â”€ lstm_classifier-epoch=XX-val_acc=0.XXXX_metadata.json  # Metadata

- 5 modelos independientes```

logs/lstm_classifier/

â””â”€â”€ version_0/- Cada participante validado exactamente 1 vez

    â””â”€â”€ events.out.tfevents...  # Logs de TensorBoard- MÃ©tricas: **Val Accuracy = Mean Â± Std** (ej: 60% Â± 12%)

```

**InterpretaciÃ³n**:

El archivo metadata.json contiene:- Mean: Accuracy esperada en nuevos participantes

- Lista de participantes train/val- Std < 10%: Modelo estable âœ…

- HiperparÃ¡metros usados- Std > 15%: Alta variabilidad (normal con N=20) âš ï¸

- Val split y random state

- Best score obtenido## ğŸ› ï¸ Stack TecnolÃ³gico



Esto permite **reproducibilidad completa** del experimento.- **Streamlit**: Framework web interactivo

- **PyTorch + Lightning**: Deep learning con logging automÃ¡tico

---- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento

- **Plotly**: GrÃ¡ficos interactivos 3D

Ver `README.md` para documentaciÃ³n completa.- **Scikit-learn**: PCA, cross-validation, metrics

- **Pandas/NumPy**: ManipulaciÃ³n de datos

## ğŸ”— Links Ãštiles

## âš¡ Tips

- **TensorBoard**: http://localhost:6006 (despuÃ©s de `tensorboard --logdir=logs/`)

- **Streamlit**: http://localhost:8501- Usa **K-Fold CV** para obtener mÃ©tricas robustas con dataset pequeÃ±o

- **DocumentaciÃ³n PyTorch Lightning**: https://lightning.ai/docs/pytorch/- Los datos se cachean automÃ¡ticamente en Streamlit (mejor rendimiento)

- **Plotly Docs**: https://plotly.com/python/- Los modelos entrenados se guardan en `models/`

- K-Fold guarda summary.json con mÃ©tricas agregadas y hiperparÃ¡metros
- Los logs se generan automÃ¡ticamente en `logs/`
- Todos los grÃ¡ficos son interactivos (zoom, pan, hover)

## ğŸ› Troubleshooting

**Error: Module not found**
```bash
pip install -r requirements.txt
```

**No se encuentra el dataset**
- Verifica que `data/data.csv` existe

**CUDA out of memory**
- Reduce batch_size (ej: 8 o 4)

**Modelo no converge**
- Aumenta learning_rate (5e-3)
- Reduce dropout (0.2)
- Aumenta max_epochs (100-200)

**Puerto 8501 ocupado**
```bash
streamlit run app.py --server.port 8502
```

---

Ver `README.md` para documentaciÃ³n completa.
