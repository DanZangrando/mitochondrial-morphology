# Quick Start Guide - Mitochondrial Morphology Analysis# Quick Start Guide - Mitochondrial Morphology Analysis



## ğŸš€ Inicio RÃ¡pido## ğŸš€ Inicio RÃ¡pido



### 1. Instalar dependencias### 1. Instalar dependencias

```bash```bash

# Crear entorno virtual (recomendado)pip install -r requirements.txt

python -m venv venv```

source venv/bin/activate  # Linux/Mac

# venv\Scripts\activate  # Windows### 2. Ejecutar la aplicaciÃ³n

```bash

# Instalar dependenciasstreamlit run app.py

pip install -r requirements.txt```

```

### 3. NavegaciÃ³n

### 2. Ejecutar la aplicaciÃ³n- **Home**: Vista general del proyecto y dataset

```bash- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo

streamlit run app.py- **ğŸ¯ PCA**: ReducciÃ³n dimensional con PCA

```- **ğŸ¤– Autoencoder**: Entrenamiento y visualizaciÃ³n del espacio latente



La aplicaciÃ³n se abrirÃ¡ en `http://localhost:8501`### 4. Entrenar el Autoencoder



### 3. NavegaciÃ³n**OpciÃ³n A**: Desde la interfaz web (pÃ¡gina Autoencoder)

- **Home**: Vista general del proyecto y dataset

- **ğŸ“Š EDA**: AnÃ¡lisis exploratorio interactivo**OpciÃ³n B**: Desde terminal

- **ğŸ¯ PCA**: ReducciÃ³n dimensional con PCA```bash

- **ğŸ“ Entrenar Modelo**: Entrenamiento de LSTM Classifier con K-Fold CVpython scripts/train_autoencoder.py

- **ğŸ¤– Clasificador**: VisualizaciÃ³n de resultados```



### 4. Entrenar el Clasificador### 5. Ver logs de entrenamiento

```bash

**OpciÃ³n A**: Desde la interfaz web (pÃ¡gina ğŸ“ Entrenar Modelo)tensorboard --logdir=logs/

- Selecciona modo: Train/Val Split Simple o **K-Fold CV (recomendado)**```

- Configura hiperparÃ¡metros (hidden_dim, learning_rate, dropout, etc.)Luego abre: http://localhost:6006

- Click en "ğŸš€ Iniciar Entrenamiento"

- Ve mÃ©tricas en tiempo real con TensorBoard## ğŸ“Š Estructura del Dataset



**OpciÃ³n B**: Desde terminal- **Observaciones**: 385 mediciones de mitocondrias

```bash- **Participantes**: 20 (10 CT, 10 ELA)

# Entrenar con K-Fold Cross-Validation (K=5 por defecto)- **Grupos**: 

python scripts/train_classifier.py  - CT (Control): 195 observaciones

```  - ELA (Esclerosis Lateral AmiotrÃ³fica): 190 observaciones

- **MÃ©tricas**: 8 features morfolÃ³gicas (IsoVol, Surface, Length, RoughSph)

### 5. Ver logs de entrenamiento- **Variables demogrÃ¡ficas**: Age, Sex, Participant

```bash

tensorboard --logdir=logs/lstm_classifier## ğŸ¯ Objetivos

```

Luego abre: http://localhost:60061. **EDA**: Identificar diferencias estadÃ­sticas entre grupos CT y ELA

2. **PCA**: Visualizar estructura de datos en espacio reducido

## ğŸ“Š Estructura del Dataset3. **Autoencoder**: Capturar relaciones no lineales y explorar clusterizaciÃ³n



- **Observaciones**: 306 mediciones de mitocondrias## ğŸ“ ConfiguraciÃ³n

- **Participantes**: 20 (10 CT, 10 ELA)

- **Grupos**: Edita `config/config.yaml` para modificar:

  - CT (Control): 167 observaciones- Arquitectura del autoencoder

  - ELA (Esclerosis Lateral AmiotrÃ³fica): 139 observaciones- HiperparÃ¡metros de entrenamiento

- **MÃ©tricas**: 8 features morfolÃ³gicas (IsoVol, Surface, Length, RoughSph - SUMA/PROM)- NÃºmero de componentes PCA

- **Variables demogrÃ¡ficas**: Age, Sex, Participant (no usadas como input del modelo)- Rutas de datos



## ğŸ¯ Objetivos## ğŸ› ï¸ Stack TecnolÃ³gico



1. **EDA**: Identificar diferencias estadÃ­sticas entre grupos CT y ELA- **Streamlit**: Framework web interactivo

2. **PCA**: Visualizar estructura de datos en espacio reducido- **PyTorch + Lightning**: Deep learning con logging automÃ¡tico

3. **LSTM Classifier**: ClasificaciÃ³n supervisada CT vs ELA usando secuencias de longitud variable- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento

4. **K-Fold CV**: Obtener mÃ©tricas robustas (mean Â± std) para dataset pequeÃ±o (N=20)- **Plotly**: GrÃ¡ficos interactivos 3D

- **Scikit-learn**: PCA y preprocesamiento

## ğŸ§  Modelo- **Pandas/NumPy**: ManipulaciÃ³n de datos



**LSTM Bidirectional Classifier**:## âš¡ Tips

- Input: (batch, seq_len, 8) - secuencias de longitud variable (4-36 mediciones/participante)

- 2 capas LSTM bidireccionales (hidden_dim=64)- Los datos se cachean automÃ¡ticamente en Streamlit (mejor rendimiento)

- Classifier head: FC 128â†’64â†’32â†’2 con Dropout- Usa `Ctrl+C` en terminal para detener la app

- Loss: Cross Entropy- Los modelos entrenados se guardan en `models/`

- Optimizer: Adam + ReduceLROnPlateau- Los logs se generan automÃ¡ticamente en `logs/`

- ~147K parÃ¡metros entrenables- Todos los grÃ¡ficos son interactivos (zoom, pan, hover)



## ğŸ“ ConfiguraciÃ³n## ğŸ› Troubleshooting



Edita `config/config.yaml` para modificar:**Error: Module not found**

- Arquitectura del clasificador```bash

- HiperparÃ¡metros de entrenamientopip install -r requirements.txt

- Callbacks (early stopping, checkpointing)```

- NÃºmero de componentes PCA

- Rutas de datos**No se encuentra el dataset**

- Verifica que `data/data.csv` existe

## ğŸ”¬ K-Fold Cross-Validation

**Error al entrenar**

**Â¿Por quÃ© K-Fold para N=20?**- Verifica instalaciÃ³n de PyTorch: `pip install torch pytorch-lightning`



Con solo 20 participantes, un train/val split simple (16/4) es muy sensible al azar. K-Fold entrena K modelos independientes y reporta mÃ©tricas robustas:**Puerto 8501 ocupado**

```bash

**K=5 (recomendado)**:streamlit run app.py --server.port 8502

- 5 modelos independientes```

- Cada participante validado exactamente 1 vez
- MÃ©tricas: **Val Accuracy = Mean Â± Std** (ej: 60% Â± 12%)

**InterpretaciÃ³n**:
- Mean: Accuracy esperada en nuevos participantes
- Std < 10%: Modelo estable âœ…
- Std > 15%: Alta variabilidad (normal con N=20) âš ï¸

## ğŸ› ï¸ Stack TecnolÃ³gico

- **Streamlit**: Framework web interactivo
- **PyTorch + Lightning**: Deep learning con logging automÃ¡tico
- **TensorBoard**: VisualizaciÃ³n de mÃ©tricas de entrenamiento
- **Plotly**: GrÃ¡ficos interactivos 3D
- **Scikit-learn**: PCA, cross-validation, metrics
- **Pandas/NumPy**: ManipulaciÃ³n de datos

## âš¡ Tips

- Usa **K-Fold CV** para obtener mÃ©tricas robustas con dataset pequeÃ±o
- Los datos se cachean automÃ¡ticamente en Streamlit (mejor rendimiento)
- Los modelos entrenados se guardan en `models/`
- K-Fold guarda summary.json con mÃ©tricas agregadas y hiperparÃ¡metros
- Los logs se generan automÃ¡ticamente en `logs/`
- Todos los grÃ¡ficos son interactivos (zoom, pan, hover)

## ğŸ› Troubleshooting

**Error: Module not found**
```bash
pip install -r requirements.txt
```

**No se encuentra el dataset**
- Verifica que `data/data.csv` existe

**CUDA out of memory**
- Reduce batch_size (ej: 8 o 4)

**Modelo no converge**
- Aumenta learning_rate (5e-3)
- Reduce dropout (0.2)
- Aumenta max_epochs (100-200)

**Puerto 8501 ocupado**
```bash
streamlit run app.py --server.port 8502
```

---

Ver `README.md` para documentaciÃ³n completa.
