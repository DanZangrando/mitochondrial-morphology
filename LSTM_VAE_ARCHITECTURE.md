# LSTM-VAE: Preservando Variabilidad Intra-Participante

## ğŸ¯ Problema Solucionado

### âŒ Problema con Mean Pooling

```python
# Mean pooling pierde informaciÃ³n valiosa
Participante 1: [medida1, medida2, ..., medida_n]
                     â†“ mean()
                 valor_Ãºnico  â† Â¡Se pierde la variabilidad!
```

**Â¿QuÃ© se pierde?**
- Variabilidad intra-participante (importante para discriminar CT vs ELA)
- Patrones temporales o espaciales en las medidas
- InformaciÃ³n sobre heterogeneidad mitocondrial

### âœ… SoluciÃ³n: LSTM-VAE

```python
# LSTM procesa la secuencia completa
Participante 1: [medida1, medida2, ..., medida_n]
                     â†“ LSTM Encoder
                 hidden_state  â† Â¡Captura toda la variabilidad!
                     â†“
                  Î¼, Ïƒ (latent)
```

**Ventajas:**
- âœ… Captura variabilidad intra-participante
- âœ… Sensible al orden/patrÃ³n de medidas
- âœ… Cada medida contribuye al embedding latente
- âœ… Reconstruye la secuencia completa (no solo un promedio)

## ğŸ—ï¸ Arquitectura LSTM-VAE

### Flujo Completo

```
Input: Secuencia de medidas por participante
[batch, seq_len, 8 features]
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   LSTM Encoder         â”‚
â”‚   Bidirectional        â”‚
â”‚   2 layers, hidden=64  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
   Final Hidden State
   [batch, 128]  (64*2 por bidireccional)
         â†“
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â†“         â†“
   Î¼ FC    logÏƒÂ² FC
  [batch, 16]  [batch, 16]
         â†“
  Reparameterization
  z = Î¼ + Ïƒ * Îµ
         â†“
    â”Œâ”€â”€â”€â”€â”´â”€â”€â”€â”€â”
    â†“         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Decoder  â”‚ â”‚ Classifier  â”‚
â”‚  LSTM    â”‚ â”‚   [32,16]   â”‚
â”‚2 layers  â”‚ â”‚  â†’2 classes â”‚
â”‚hidden=64 â”‚ â”‚             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“             â†“
ReconstrucciÃ³n   CT/ELA
de secuencia    prediction
```

### Componentes Detallados

#### 1. LSTM Encoder

```python
self.encoder_lstm = nn.LSTM(
    input_size=8,           # 8 features morfolÃ³gicas
    hidden_size=64,         # DimensiÃ³n hidden
    num_layers=2,           # Stack de 2 LSTMs
    batch_first=True,       # Input: [batch, seq, features]
    dropout=0.3,            # Dropout entre layers
    bidirectional=True      # Lee secuencia en ambas direcciones
)
```

**Â¿QuÃ© hace?**
- Procesa cada medida secuencialmente
- Mantiene "memoria" de medidas anteriores en hidden state
- Bidireccional: lee forward y backward
- Final hidden state = representaciÃ³n de toda la secuencia

#### 2. Latent Space Projection

```python
# Desde el Ãºltimo hidden state del LSTM
h_final = concat([h_forward, h_backward])  # [batch, 128]

Î¼ = fc_mu(h_final)           # [batch, 16]
log ÏƒÂ² = fc_logvar(h_final)  # [batch, 16]
```

**Reparameterization Trick:**
```python
z = Î¼ + exp(0.5 * log ÏƒÂ²) * Îµ,  donde Îµ ~ N(0,1)
```

Esto permite:
- Backpropagation a travÃ©s de sampling
- Espacio latente probabilÃ­stico (distribuciÃ³n, no punto fijo)

#### 3. LSTM Decoder

```python
# Inicializar decoder hidden state desde z
h_0, c_0 = latent_to_hidden(z)  # [layers, batch, hidden]

# Expandir z para cada paso temporal
decoder_input = z.repeat(1, seq_len, 1)  # [batch, seq_len, latent_dim]

# Decodificar
lstm_out, _ = decoder_lstm(decoder_input, (h_0, c_0))

# Proyectar a features originales
recon = fc_decoder(lstm_out)  # [batch, seq_len, 8]
```

**Reconstruye:**
- Toda la secuencia de medidas
- No solo un valor agregado
- Captura la variabilidad original

#### 4. Classifier Head

```python
classifier(z) â†’ [batch, 2]  # CT=0, ELA=1
```

Predice el grupo directamente desde el espacio latente.

## ğŸ“Š Manejo de Secuencias Variables

### Problema: Longitudes Diferentes

```
Participante 1: 25 medidas
Participante 2: 15 medidas  â† Diferente longitud
Participante 3: 30 medidas
```

### SoluciÃ³n: Padding + Pack/Unpack

```python
class ParticipantSequenceDataset:
    def __getitem__(self, idx):
        seq = self.sequences[idx]      # Variable length
        length = len(seq)
        return seq, length, label
```

```python
def collate_sequences(batch):
    # Encontrar max length en el batch
    max_len = max(lengths)
    
    # Pad todas las secuencias al max_len con zeros
    padded_seqs = pad_sequences(sequences, max_len)
    
    return padded_seqs, lengths, labels
```

```python
def encode(self, x, lengths):
    # Pack: ignora posiciones paddeadas
    packed = pack_padded_sequence(x, lengths, batch_first=True)
    
    # LSTM procesa solo posiciones reales
    _, (h_n, c_n) = self.encoder_lstm(packed)
    
    # h_n contiene el estado al final de cada secuencia real
    return h_n
```

**Ventajas:**
- âœ… Eficiente: no procesa padding
- âœ… Correcto: hidden state al final de secuencia real
- âœ… Flexible: soporta cualquier longitud

## ğŸ”¢ FunciÃ³n de PÃ©rdida

### Loss Total

```python
L_total = L_recon + Î± * L_KL + Î² * L_class

donde:
  Î± = 0.0001  (mÃ¡s bajo que en VAE estÃ¡ndar)
  Î² = 1.0
```

### 1. Reconstruction Loss

```python
# Solo para posiciones reales (no padding)
L_recon = 0
for cada participante i:
    seq_len_i = lengths[i]
    L_recon += MSE(
        recon[i, :seq_len_i, :],  # Solo hasta seq_len_i
        original[i, :seq_len_i, :]
    )
L_recon /= batch_size
```

**Importante:** Ignora posiciones paddeadas en la pÃ©rdida.

### 2. KL Divergence

```python
L_KL = -0.5 * Î£(1 + log(ÏƒÂ²) - Î¼Â² - ÏƒÂ²)
```

**Î± mÃ¡s bajo (0.0001 vs 0.001)** porque:
- Secuencias tienen mÃ¡s informaciÃ³n
- Evita "posterior collapse" (Î¼=0, Ïƒ=1 trivial)

### 3. Classification Loss

```python
L_class = CrossEntropy(classifier(z), true_label)
```

## ğŸ“ˆ Ventajas sobre VAE EstÃ¡ndar

| Aspecto | VAE EstÃ¡ndar | LSTM-VAE |
|---------|--------------|----------|
| **InformaciÃ³n preservada** | Solo promedio | Secuencia completa |
| **Variabilidad** | âŒ Se pierde | âœ… Capturada |
| **Heterogeneidad** | âŒ Colapsada | âœ… Representada |
| **ReconstrucciÃ³n** | 1 vector agregado | n medidas |
| **ParÃ¡metros** | ~6,700 | ~50,000 |
| **Complejidad** | Baja | Alta |
| **Training time** | RÃ¡pido | MÃ¡s lento |
| **Interpretabilidad** | Alta | Media |

## ğŸš€ Uso

### Entrenar LSTM-VAE

```bash
# Con flag --lstm
python scripts/train_autoencoder.py --lstm

# O equivalentemente
python scripts/train_autoencoder.py -l
```

### Entrenar VAE EstÃ¡ndar (mean pooling)

```bash
# Sin flags
python scripts/train_autoencoder.py
```

### Comparar Ambos

```bash
# Entrenar VAE estÃ¡ndar
python scripts/train_autoencoder.py
# â†’ models/vae-*.ckpt

# Entrenar LSTM-VAE
python scripts/train_autoencoder.py --lstm
# â†’ models/lstm_vae-*.ckpt
```

Luego comparar en Streamlit:
- Accuracy de clasificaciÃ³n
- Espacio latente (clusterizaciÃ³n)
- Calidad de reconstrucciÃ³n

## ğŸ”¬ InterpretaciÃ³n

### Â¿CuÃ¡ndo LSTM-VAE es mejor?

Si **val_acc(LSTM-VAE) > val_acc(VAE)**:
- âœ… La variabilidad intra-participante es informativa
- âœ… Patrones en secuencias distinguen CT vs ELA
- âœ… Heterogeneidad mitocondrial es relevante

### Â¿CuÃ¡ndo VAE estÃ¡ndar es suficiente?

Si **val_acc(VAE) â‰ˆ val_acc(LSTM-VAE)**:
- El promedio captura la informaciÃ³n relevante
- Variabilidad es ruido, no seÃ±al
- VAE estÃ¡ndar es mÃ¡s simple y rÃ¡pido

## ğŸ“Š HiperparÃ¡metros LSTM-VAE

```python
LSTMVariationalAutoencoder(
    input_dim=8,              # Features por medida
    hidden_dim=64,            # LSTM hidden dimension
    num_lstm_layers=2,        # Profundidad del LSTM
    latent_dim=16,            # Espacio latente (mÃ¡s grande)
    classifier_layers=[32, 16],  # Clasificador mÃ¡s profundo
    num_classes=2,            # CT vs ELA
    learning_rate=0.0005,     # LR adaptativo
    kl_weight=0.0001,         # KL bajo (evitar collapse)
    classification_weight=1.0,
    dropout_rate=0.3,         # Dropout alto (secuencias)
    bidirectional=True        # Lee en ambas direcciones
)
```

### JustificaciÃ³n

- **hidden_dim=64**: Balance capacidad/overfitting
- **num_layers=2**: Captura patrones jerÃ¡rquicos
- **latent_dim=16**: MÃ¡s grande que VAE (8) para capturar variabilidad
- **bidirectional=True**: Contexto completo de secuencia
- **kl_weight=0.0001**: Evita colapso a N(0,1) trivial
- **dropout=0.3**: RegularizaciÃ³n fuerte (secuencias overfit fÃ¡cil)

## ğŸ’¡ AnÃ¡lisis Esperados

### 1. Variabilidad Intra-Participante

```python
# En el espacio latente, Â¿la "incertidumbre" (Ïƒ) difiere entre grupos?
Ïƒ_CT = latent_logvar[labels==CT].mean()
Ïƒ_ELA = latent_logvar[labels==ELA].mean()

if Ïƒ_ELA > Ïƒ_CT:
    print("ELA tiene mayor heterogeneidad mitocondrial")
```

### 2. ReconstrucciÃ³n de Secuencias

```python
# Â¿El modelo captura patrones en la secuencia?
plot_sequence_reconstruction(
    original=seq_original,
    reconstructed=seq_recon
)
# Buscar: Â¿mantiene tendencias, picos, variaciones?
```

### 3. Importancia de Cada Medida

```python
# AtenciÃ³n implÃ­cita del LSTM
# Â¿QuÃ© medidas contribuyen mÃ¡s al hidden state?
attention_weights = analyze_lstm_attention(model, sequences)
```

## ğŸ“ Referencias

- **LSTM**: Hochreiter & Schmidhuber (1997)
- **VAE**: Kingma & Welling (2013)
- **VAE-RNN**: Chung et al. (2015) - "A Recurrent Latent Variable Model for Sequential Data"
- **Bidirectional LSTM**: Schuster & Paliwal (1997)

## ğŸ“ Notas TÃ©cnicas

### Gradient Clipping

```python
trainer = pl.Trainer(
    gradient_clip_val=1.0  # Evita exploding gradients en LSTM
)
```

Las LSTMs pueden sufrir de gradientes explosivos, especialmente con secuencias largas.

### Batch Size

```python
batch_size = 4  # MÃ¡s pequeÃ±o que VAE estÃ¡ndar (16)
```

Secuencias usan mÃ¡s memoria. Ajustar segÃºn GPU disponible.

### Sequence Length Distribution

```
Participante | Medidas
-------------|--------
1            | 10
2            | 25  â† MÃ¡ximo en batch
3            | 15
4            | 20

â†’ Padding: todas a 25
â†’ LSTM ignora padding con pack_padded_sequence
```

## ğŸ”® Extensiones Futuras

1. **Attention Mechanism**: PonderaciÃ³n explÃ­cita de medidas importantes
2. **Variational RNN**: Modelo mÃ¡s sofisticado (cada timestep tiene latent)
3. **Hierarchical VAE**: Latent por medida + latent global por participante
4. **Conditional LSTM-VAE**: Condicionar en Age, Sex, etc.

---

**Resumen:** LSTM-VAE preserva toda la riqueza de informaciÃ³n de las medidas individuales, capturando variabilidad intra-participante que puede ser crucial para discriminar entre CT y ELA. Es mÃ¡s complejo que el VAE estÃ¡ndar, pero potencialmente mÃ¡s poderoso si esa variabilidad es informativa.
