# Arquitectura VAE para MorfologÃ­a Mitocondrial

## ğŸ¯ Objetivo

Utilizar un **Variational Autoencoder (VAE)** con clasificaciÃ³n integrada para:

1. Aprender representaciones latentes de mÃ©tricas morfolÃ³gicas mitocondriales
2. Clasificar participantes en grupos CT (Control) vs ELA (Esclerosis Lateral AmiotrÃ³fica)
3. Explorar el espacio latente para encontrar patrones discriminativos

## ğŸ—ï¸ Arquitectura

### Componentes Principales

```
Input (8 features)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Encoder Network   â”‚
â”‚   [64] â†’ [32]       â”‚
â”‚   BatchNorm + ReLU  â”‚
â”‚   + Dropout(0.2)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“           â†“
   [Î¼]       [log ÏƒÂ²]  â† Latent parameters
    â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
          â†“
    Reparameterization
    z = Î¼ + Ïƒ * Îµ
          â†“
    â”Œâ”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”
    â†“           â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Decoder   â”‚ â”‚ Classifier   â”‚
â”‚  [32]â†’[64] â”‚ â”‚    [16]      â”‚
â”‚  â†’8 feat   â”‚ â”‚  â†’2 classes  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Detalles TÃ©cnicos

**Encoder:**
- Input: 8 features (mÃ©tricas morfolÃ³gicas estandarizadas)
- Hidden: [64, 32] con BatchNorm + ReLU + Dropout(0.2)
- Output: Î¼ (mean) y log ÏƒÂ² (log variance) del espacio latente (8D)

**Reparameterization Trick:**
```python
z = Î¼ + Ïƒ * Îµ, donde Îµ ~ N(0, 1)
```
Permite backpropagation a travÃ©s de muestras aleatorias.

**Decoder:**
- Input: Latent vector z (8D)
- Hidden: [32, 64] con BatchNorm + ReLU + Dropout(0.2)
- Output: ReconstrucciÃ³n de las 8 features

**Classifier:**
- Input: Latent vector z (8D)
- Hidden: [16] con BatchNorm + ReLU + Dropout(0.2)
- Output: Logits para 2 clases (CT=0, ELA=1)

## ğŸ“Š Manejo de Datos

### Problema: MÃºltiples Medidas por Participante

Cada participante tiene **n medidas distintas** (observaciones independientes de mitocondrias). 

**SoluciÃ³n implementada:**
```python
# AgregaciÃ³n por participante (mean pooling)
data_agg = data.groupby('Participant').agg({
    'PROM IsoVol': 'mean',
    'PROM Surface': 'mean',
    # ... resto de features
})
```

**Ventajas:**
- âœ… Evita data leakage (medidas del mismo participante no aparecen en train y val)
- âœ… Cada sample representa un participante completo
- âœ… ClasificaciÃ³n a nivel de participante (mÃ¡s interpretable)

**Alternativas consideradas:**
- âŒ Usar todas las medidas individualmente â†’ data leakage
- âŒ Attention mechanism â†’ complejidad innecesaria para este dataset

### Split Train/Validation

```python
# Split por participantes (no por medidas)
train_participants = 80% 
val_participants = 20%
```

Esto garantiza que todas las medidas de un participante estÃ¡n en train O en val, nunca en ambos.

## ğŸ”¢ FunciÃ³n de PÃ©rdida

El VAE combina 3 componentes de pÃ©rdida:

### 1. Reconstruction Loss (MSE)
```python
L_recon = MSE(x_reconstructed, x_original)
```
QuÃ© tan bien el decoder reconstruye el input.

### 2. KL Divergence Loss
```python
L_KL = -0.5 * Î£(1 + log(ÏƒÂ²) - Î¼Â² - ÏƒÂ²)
```
Regulariza el espacio latente hacia N(0,1). Permite:
- Espacios latentes continuos
- InterpolaciÃ³n suave
- GeneraciÃ³n de nuevos datos

### 3. Classification Loss (Cross-Entropy)
```python
L_class = CrossEntropy(predicted_class, true_class)
```
Entrena el clasificador para predecir CT vs ELA.

### PÃ©rdida Total
```python
L_total = L_recon + Î± * L_KL + Î² * L_class

Î± = 0.001  # KL weight (bajo para evitar "posterior collapse")
Î² = 1.0    # Classification weight
```

## ğŸ“ Entrenamiento

### HiperparÃ¡metros

```yaml
batch_size: 16          # PequeÃ±o porque son participantes agregados
learning_rate: 0.0005   # Bajo para estabilidad del VAE
max_epochs: 200         # VAEs necesitan mÃ¡s Ã©pocas
early_stopping: 20      # Paciencia aumentada
optimizer: AdamW        # Con weight_decay=0.01
scheduler: ReduceLROnPlateau
```

### Callbacks

1. **EarlyStopping**: Para en `val_loss` con patience=20
2. **ModelCheckpoint**: Guarda top-3 modelos por `val_loss`
3. **LearningRateMonitor**: Registra LR en TensorBoard

### MÃ©tricas Monitoreadas

Durante entrenamiento se registran:
- `train_loss`, `val_loss` (total)
- `train_recon`, `val_recon` (reconstrucciÃ³n)
- `train_kl`, `val_kl` (KL divergence)
- `train_class_loss`, `val_class_loss` (clasificaciÃ³n)
- `train_acc`, `val_acc` (accuracy de clasificaciÃ³n)

## ğŸ“ˆ InterpretaciÃ³n

### Espacio Latente

El espacio latente 8D captura:
- Patrones morfolÃ³gicos mitocondriales
- InformaciÃ³n discriminativa entre CT/ELA
- Estructura probabilÃ­stica (Î¼, Ïƒ) en lugar de puntos fijos

**VisualizaciÃ³n:**
- Proyecciones 2D/3D usando primeras dimensiones latentes
- Colorear por: Group, Prediction, Correcto, Sex
- Buscar clusterizaciÃ³n de grupos

### ClasificaciÃ³n

Si el modelo alcanza **accuracy > 70%**, indica que:
- Las mÃ©tricas morfolÃ³gicas tienen poder discriminativo
- El espacio latente captura diferencias entre CT/ELA
- Hay patrones subyacentes en la morfologÃ­a mitocondrial

### ComparaciÃ³n con PCA

| Aspecto | PCA | VAE |
|---------|-----|-----|
| Tipo | Lineal | No lineal |
| Complejidad | Baja | Alta |
| Interpretabilidad | Alta | Media |
| ClasificaciÃ³n | No | SÃ­ (integrada) |
| GeneraciÃ³n | No | SÃ­ |
| Mejor para | EDA rÃ¡pido | AnÃ¡lisis profundo |

## ğŸš€ Uso

### Entrenar

```bash
# OpciÃ³n 1: Desde terminal
python scripts/train_autoencoder.py

# OpciÃ³n 2: Desde Streamlit
streamlit run app.py
# â†’ Ir a pÃ¡gina "ğŸ¤– Autoencoder"
# â†’ Click "ğŸš€ Entrenar Autoencoder"
```

### Monitorear

```bash
tensorboard --logdir=logs/
# Abrir http://localhost:6006
```

### Evaluar

```bash
streamlit run app.py
# â†’ PÃ¡gina "ğŸ¤– Autoencoder"
# â†’ Seleccionar modelo entrenado
# â†’ Ver accuracy, matriz de confusiÃ³n, espacio latente
```

## ğŸ“š Referencias

**InspiraciÃ³n:**
- Nature Methods paper on quantized VAEs for biological data
- VAE original paper: Kingma & Welling (2013)
- PyTorch Lightning documentation

**ImplementaciÃ³n:**
- `src/autoencoder.py`: CÃ³digo del modelo VAE
- `scripts/train_autoencoder.py`: Script de entrenamiento
- `pages/3_ğŸ¤–_Autoencoder.py`: Interfaz Streamlit
- `config/config.yaml`: ConfiguraciÃ³n de hiperparÃ¡metros

## ğŸ’¡ PrÃ³ximos Pasos

**Mejoras posibles:**
1. **Î²-VAE**: Aumentar peso de KL para espacio latente mÃ¡s disentangled
2. **Attention mechanism**: Para ponderar medidas por participante
3. **Conditional VAE**: Condicionar en Sex o Age
4. **Ensemble**: Combinar mÃºltiples VAEs entrenados
5. **Transfer learning**: Pre-entrenar en dataset mÃ¡s grande

**AnÃ¡lisis adicionales:**
1. Importancia de features (gradient-based)
2. InterpolaciÃ³n en espacio latente
3. GeneraciÃ³n de muestras sintÃ©ticas
4. AnÃ¡lisis de dimensiones latentes individuales
